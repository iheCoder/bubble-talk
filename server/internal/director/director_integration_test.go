package director

import (
	"bubble-talk/server/internal/config"
	"bubble-talk/server/internal/llm"
	"bubble-talk/server/internal/model"
	"os"
	"testing"
	"time"
)

// TestRealLLMOpenAI æµ‹è¯•çœŸå® OpenAI LLM çš„å¯¼æ¼”å†³ç­–
// éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡: LLM_API_KEY
// è¿è¡Œ: go test -v -run TestRealLLMOpenAI ./server/internal/director/... -tags=integration
func TestRealLLMOpenAI(t *testing.T) {
	// è·³è¿‡æ¡ä»¶ï¼šæ²¡æœ‰ API Key æˆ–æ²¡æœ‰æŒ‡å®š -tags=integration
	//apiKey := os.Getenv("LLM_API_KEY")
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		t.Skip("â­ï¸  Skipping real LLM test: LLM_API_KEY not set")
	}

	// åˆ›å»ºé…ç½®
	cfg := &config.Config{
		LLM: config.LLMConfig{
			Provider: "openai",
			OpenAI: config.LLMProviderConfig{
				APIKey:      apiKey,
				APIURL:      "https://api.openai.com/v1",
				Model:       "gpt-4o-mini", // ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
				Temperature: 0.7,
				MaxTokens:   2000,
			},
		},
		Director: config.DirectorConfig{
			EnableLLM:              true,
			AvailableRoles:         []string{"host", "economist", "skeptic"},
			AvailableBeats:         []string{"reveal", "check", "deepen", "twist", "continue", "lens_shift", "feynman", "montage", "minigame", "exit_ticket"},
			DefaultTalkBurstLimit:  20,
			HighLoadTalkBurstLimit: 15,
			OutputClockThreshold:   90,
		},
	}

	// åˆ›å»ºçœŸå® LLM å®¢æˆ·ç«¯
	llmClient, err := llm.NewClient(cfg)
	if err != nil {
		t.Fatalf("âŒ Failed to create LLM client: %v", err)
	}

	// åˆ›å»ºå¯¼æ¼”å¼•æ“
	director := NewDirectorEngine(cfg, llmClient)

	// åœºæ™¯ 1: ç”¨æˆ·æœ‰è¯¯è§£ï¼Œéœ€è¦æ•‘åœº
	t.Run("Scenario1_UserMisunderstanding", func(t *testing.T) {
		state := &model.SessionState{
			SessionID:         "real-test-1",
			EntryID:           "econ_opportunity_cost",
			AvailableRoles:    []string{"host", "economist", "skeptic"},
			MasteryEstimate:   0.3,
			OutputClockSec:    45,
			TensionLevel:      6,
			CognitiveLoad:     7,
			MisconceptionTags: []string{"M1_cost_equals_money_spent"},
			Signals: model.SignalsSnapshot{
				LastUserChars:     25,
				LastUserLatencyMS: 3000,
			},
			Turns: []model.Turn{
				{Role: "user", Text: "æœºä¼šæˆæœ¬æ˜¯ä»€ä¹ˆï¼Ÿ", TS: time.Now()},
				{Role: "assistant", Text: "æœºä¼šæˆæœ¬æ˜¯å½“ä½ åšå‡ºé€‰æ‹©æ—¶æ”¾å¼ƒçš„æœ€å¥½æ›¿ä»£é€‰æ‹©çš„ä»·å€¼...", TS: time.Now().Add(-10 * time.Second)},
				{Role: "user", Text: "æ‰€ä»¥å°±æ˜¯èŠ±æ‰çš„é’±å—ï¼Ÿ", TS: time.Now()},
			},
		}

		userInput := "æ‰€ä»¥æœºä¼šæˆæœ¬ç­‰äºæ”¯å‡ºæˆæœ¬ï¼Ÿ"

		plan := director.Decide(state, userInput)

		// éªŒè¯å…³é”®å­—æ®µ
		if plan.FlowMode == "" {
			t.Error("âŒ flow_mode should not be empty")
		}
		if plan.NextBeat == "" {
			t.Error("âŒ next_beat should not be empty")
		}
		if plan.NextRole == "" {
			t.Error("âŒ next_role should not be empty")
		}

		// éªŒè¯ RESCUE æ¨¡å¼ï¼ˆæœ‰è¯¯è§£ï¼‰
		if plan.FlowMode != "RESCUE" {
			t.Logf("âš ï¸  Expected RESCUE mode, got %s (still valid, just different strategy)", plan.FlowMode)
		}

		t.Logf("âœ… Real LLM Decision:")
		t.Logf("   FlowMode: %s", plan.FlowMode)
		t.Logf("   UserMindState: %v", plan.UserMindState)
		t.Logf("   NextBeat: %s", plan.NextBeat)
		t.Logf("   NextRole: %s", plan.NextRole)
		t.Logf("   OutputAction: %s", plan.OutputAction)
		t.Logf("   Notes: %s", plan.Notes)
		if plan.Debug != nil {
			t.Logf("   BeatChoiceReason: %s", plan.Debug.BeatChoiceReason)
		}
	})

	// åœºæ™¯ 2: ç”¨æˆ·é¡ºæµçŠ¶æ€ï¼Œå°æ­¥æ¨è¿›
	t.Run("Scenario2_FlowState", func(t *testing.T) {
		state := &model.SessionState{
			SessionID:         "real-test-2",
			EntryID:           "econ_opportunity_cost",
			AvailableRoles:    []string{"host", "economist", "skeptic"},
			MasteryEstimate:   0.6,
			OutputClockSec:    35,
			TensionLevel:      4,
			CognitiveLoad:     4,
			MisconceptionTags: []string{},
			Signals: model.SignalsSnapshot{
				LastUserChars:     80,
				LastUserLatencyMS: 1500,
			},
			Turns: []model.Turn{
				{Role: "user", Text: "æœºä¼šæˆæœ¬æ˜¯æ”¾å¼ƒçš„æœ€å¥½æ›¿ä»£é€‰æ‹©çš„ä»·å€¼", TS: time.Now()},
				{Role: "assistant", Text: "å®Œå…¨æ­£ç¡®ï¼ä½ ç†è§£å¾—å¾ˆåˆ°ä½", TS: time.Now().Add(-8 * time.Second)},
				{Role: "user", Text: "å¯¹ï¼Œå°±æ˜¯è¿™æ ·", TS: time.Now()},
			},
		}

		userInput := "é‚£å¦‚æœæˆ‘è¦è¯„ä¼°ä¹°æˆ¿çš„æœºä¼šæˆæœ¬å‘¢ï¼Ÿ"

		plan := director.Decide(state, userInput)

		// éªŒè¯å…³é”®å­—æ®µ
		if plan.FlowMode == "" {
			t.Error("âŒ flow_mode should not be empty")
		}
		if plan.NextBeat == "" {
			t.Error("âŒ next_beat should not be empty")
		}

		t.Logf("âœ… Real LLM Decision (Flow State):")
		t.Logf("   FlowMode: %s", plan.FlowMode)
		t.Logf("   UserMindState: %v", plan.UserMindState)
		t.Logf("   NextBeat: %s", plan.NextBeat)
		t.Logf("   NextRole: %s", plan.NextRole)
		t.Logf("   OutputAction: %s", plan.OutputAction)
		t.Logf("   Notes: %s", plan.Notes)
	})

	// åœºæ™¯ 3: ç”¨æˆ·ç–²æƒ«ï¼Œé™ä½è´Ÿè·
	t.Run("Scenario3_UserFatigue", func(t *testing.T) {
		state := &model.SessionState{
			SessionID:         "real-test-3",
			EntryID:           "econ_opportunity_cost",
			AvailableRoles:    []string{"host", "economist", "skeptic"},
			MasteryEstimate:   0.5,
			OutputClockSec:    60,
			TensionLevel:      6,
			CognitiveLoad:     8,
			MisconceptionTags: []string{},
			Signals: model.SignalsSnapshot{
				LastUserChars:     3,    // å¾ˆçŸ­çš„è¾“å‡º
				LastUserLatencyMS: 8000, // å¾ˆé•¿çš„å»¶è¿Ÿ
			},
			Turns: []model.Turn{
				{Role: "user", Text: "...", TS: time.Now()},
			},
		}

		userInput := "å—¯"

		plan := director.Decide(state, userInput)

		// éªŒè¯å…³é”®å­—æ®µ
		if plan.FlowMode == "" {
			t.Error("âŒ flow_mode should not be empty")
		}
		if plan.NextBeat == "" {
			t.Error("âŒ next_beat should not be empty")
		}

		// ç–²æƒ«çŠ¶æ€åº”è¯¥å€¾å‘äº minigame æˆ– exit_ticket
		isLowLoadBeat := plan.NextBeat == "minigame" || plan.NextBeat == "exit_ticket"
		if !isLowLoadBeat {
			t.Logf("âš ï¸  Expected low-load beat (minigame/exit_ticket), got %s (still valid)", plan.NextBeat)
		}

		t.Logf("âœ… Real LLM Decision (Fatigue State):")
		t.Logf("   FlowMode: %s", plan.FlowMode)
		t.Logf("   UserMindState: %v", plan.UserMindState)
		t.Logf("   NextBeat: %s (should be low-load)", plan.NextBeat)
		t.Logf("   TalkBurstLimitSec: %d (should be short)", plan.TalkBurstLimitSec)
	})

	// åœºæ™¯ 4: è¾“å‡ºæ—¶é’Ÿè¶…æ—¶ï¼Œå¼ºåˆ¶è¾“å‡ºå‹ Beat
	t.Run("Scenario4_OutputClockTimeout", func(t *testing.T) {
		state := &model.SessionState{
			SessionID:         "real-test-4",
			EntryID:           "econ_opportunity_cost",
			AvailableRoles:    []string{"host", "economist", "skeptic"},
			MasteryEstimate:   0.7,
			OutputClockSec:    100, // è¶…è¿‡ 90 ç§’é˜ˆå€¼
			TensionLevel:      5,
			CognitiveLoad:     5,
			MisconceptionTags: []string{},
			Signals: model.SignalsSnapshot{
				LastUserChars:     50,
				LastUserLatencyMS: 2000,
			},
			Turns: []model.Turn{
				{Role: "user", Text: "æˆ‘æƒ³æˆ‘ç†è§£äº†", TS: time.Now()},
			},
		}

		userInput := "å¯ä»¥ç»“æŸäº†å—ï¼Ÿ"

		plan := director.Decide(state, userInput)

		// è¾“å‡ºæ—¶é’Ÿè¶…æ—¶åº”è¯¥å¼ºåˆ¶é€‰æ‹©è¾“å‡ºå‹ Beat
		isOutputBeat := plan.NextBeat == "check" || plan.NextBeat == "feynman" || plan.NextBeat == "exit_ticket"
		if !isOutputBeat {
			t.Logf("âš ï¸  Expected output beat (check/feynman/exit_ticket), got %s", plan.NextBeat)
		}

		t.Logf("âœ… Real LLM Decision (Timeout):")
		t.Logf("   OutputClock: %d sec (threshold: 90)", state.OutputClockSec)
		t.Logf("   NextBeat: %s (should be output-forcing)", plan.NextBeat)
		t.Logf("   FlowMode: %s", plan.FlowMode)
	})
}

// TestRealLLMClaude æµ‹è¯•çœŸå® Claude LLM çš„å¯¼æ¼”å†³ç­–
// éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡: ANTHROPIC_API_KEY
// è¿è¡Œ: go test -v -run TestRealLLMClaude ./server/internal/director/... -tags=integration
func TestRealLLMClaude(t *testing.T) {
	// è·³è¿‡æ¡ä»¶
	apiKey := os.Getenv("ANTHROPIC_API_KEY")
	if apiKey == "" {
		t.Skip("â­ï¸  Skipping Claude LLM test: ANTHROPIC_API_KEY not set")
	}

	// åˆ›å»ºé…ç½®
	cfg := &config.Config{
		LLM: config.LLMConfig{
			Provider: "anthropic",
			Anthropic: config.LLMProviderConfig{
				APIKey:      apiKey,
				APIURL:      "https://api.anthropic.com/v1",
				Model:       "claude-3-5-sonnet-20241022",
				Temperature: 0.7,
				MaxTokens:   2000,
			},
		},
		Director: config.DirectorConfig{
			EnableLLM:              true,
			AvailableRoles:         []string{"host", "economist", "skeptic"},
			AvailableBeats:         []string{"reveal", "check", "deepen", "twist", "continue", "lens_shift", "feynman", "montage", "minigame", "exit_ticket"},
			DefaultTalkBurstLimit:  20,
			HighLoadTalkBurstLimit: 15,
			OutputClockThreshold:   90,
		},
	}

	// åˆ›å»ºçœŸå® LLM å®¢æˆ·ç«¯
	llmClient, err := llm.NewClient(cfg)
	if err != nil {
		t.Fatalf("âŒ Failed to create Claude client: %v", err)
	}

	// åˆ›å»ºå¯¼æ¼”å¼•æ“
	director := NewDirectorEngine(cfg, llmClient)

	// æµ‹è¯•åœºæ™¯
	state := &model.SessionState{
		SessionID:         "real-claude-test",
		EntryID:           "econ_opportunity_cost",
		AvailableRoles:    []string{"host", "economist", "skeptic"},
		MasteryEstimate:   0.45,
		OutputClockSec:    50,
		TensionLevel:      5,
		CognitiveLoad:     6,
		MisconceptionTags: []string{"M1_cost_equals_money_spent"},
		Signals: model.SignalsSnapshot{
			LastUserChars:     40,
			LastUserLatencyMS: 2500,
		},
		Turns: []model.Turn{
			{Role: "user", Text: "æœºä¼šæˆæœ¬åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ", TS: time.Now()},
		},
	}

	userInput := "è¿˜æ˜¯ä¸å¤ªæ˜ç™½"

	plan := director.Decide(state, userInput)

	// éªŒè¯å…³é”®å­—æ®µ
	if plan.FlowMode == "" {
		t.Error("âŒ flow_mode should not be empty")
	}
	if plan.NextBeat == "" {
		t.Error("âŒ next_beat should not be empty")
	}
	if plan.NextRole == "" {
		t.Error("âŒ next_role should not be empty")
	}

	t.Logf("âœ… Claude LLM Decision:")
	t.Logf("   FlowMode: %s", plan.FlowMode)
	t.Logf("   UserMindState: %v", plan.UserMindState)
	t.Logf("   NextBeat: %s", plan.NextBeat)
	t.Logf("   NextRole: %s", plan.NextRole)
	t.Logf("   OutputAction: %s", plan.OutputAction)
	t.Logf("   Notes: %s", plan.Notes)
}

// TestRealLLMComparisonOpenAIVsClaude æ¯”è¾ƒ OpenAI å’Œ Claude çš„å†³ç­–å·®å¼‚
// éœ€è¦åŒæ—¶è®¾ç½® LLM_API_KEY å’Œ ANTHROPIC_API_KEY
// è¿è¡Œ: go test -v -run TestRealLLMComparisonOpenAIVsClaude ./server/internal/director/... -tags=integration
func TestRealLLMComparisonOpenAIVsClaude(t *testing.T) {
	openaiKey := os.Getenv("LLM_API_KEY")
	claudeKey := os.Getenv("ANTHROPIC_API_KEY")

	if openaiKey == "" || claudeKey == "" {
		t.Skip("â­ï¸  Skipping comparison test: both LLM_API_KEY and ANTHROPIC_API_KEY required")
	}

	// ç»Ÿä¸€çš„æµ‹è¯•çŠ¶æ€
	state := &model.SessionState{
		SessionID:         "comparison-test",
		EntryID:           "econ_opportunity_cost",
		AvailableRoles:    []string{"host", "economist", "skeptic"},
		MasteryEstimate:   0.35,
		OutputClockSec:    45,
		TensionLevel:      5,
		CognitiveLoad:     7,
		MisconceptionTags: []string{"M1_cost_equals_money_spent"},
		Signals: model.SignalsSnapshot{
			LastUserChars:     35,
			LastUserLatencyMS: 3000,
		},
		Turns: []model.Turn{
			{Role: "user", Text: "æœºä¼šæˆæœ¬æ˜¯æˆ‘èŠ±çš„é’±å§ï¼Ÿ", TS: time.Now()},
		},
	}

	userInput := "å¯¹å—ï¼Ÿ"

	// OpenAI å†³ç­–
	openaiCfg := &config.Config{
		LLM: config.LLMConfig{
			Provider: "openai",
			OpenAI: config.LLMProviderConfig{
				APIKey:      openaiKey,
				APIURL:      "https://api.openai.com/v1",
				Model:       "gpt-4o-mini",
				Temperature: 0.7,
				MaxTokens:   2000,
			},
		},
		Director: config.DirectorConfig{
			EnableLLM:              true,
			AvailableRoles:         []string{"host", "economist", "skeptic"},
			AvailableBeats:         []string{"reveal", "check", "deepen", "twist", "continue", "lens_shift", "feynman", "montage", "minigame", "exit_ticket"},
			DefaultTalkBurstLimit:  20,
			HighLoadTalkBurstLimit: 15,
			OutputClockThreshold:   90,
		},
	}

	openaiClient, _ := llm.NewClient(openaiCfg)
	openaiDirector := NewDirectorEngine(openaiCfg, openaiClient)
	openaiPlan := openaiDirector.Decide(state, userInput)

	// Claude å†³ç­–
	claudeCfg := &config.Config{
		LLM: config.LLMConfig{
			Provider: "anthropic",
			Anthropic: config.LLMProviderConfig{
				APIKey:      claudeKey,
				APIURL:      "https://api.anthropic.com/v1",
				Model:       "claude-3-5-sonnet-20241022",
				Temperature: 0.7,
				MaxTokens:   2000,
			},
		},
		Director: config.DirectorConfig{
			EnableLLM:              true,
			AvailableRoles:         []string{"host", "economist", "skeptic"},
			AvailableBeats:         []string{"reveal", "check", "deepen", "twist", "continue", "lens_shift", "feynman", "montage", "minigame", "exit_ticket"},
			DefaultTalkBurstLimit:  20,
			HighLoadTalkBurstLimit: 15,
			OutputClockThreshold:   90,
		},
	}

	claudeClient, _ := llm.NewClient(claudeCfg)
	claudeDirector := NewDirectorEngine(claudeCfg, claudeClient)
	claudePlan := claudeDirector.Decide(state, userInput)

	// æ¯”è¾ƒ
	t.Logf("ğŸ“Š LLM å†³ç­–å¯¹æ¯”:")
	t.Logf("")
	t.Logf("OpenAI (GPT-4o-mini):")
	t.Logf("  FlowMode: %s", openaiPlan.FlowMode)
	t.Logf("  UserMindState: %v", openaiPlan.UserMindState)
	t.Logf("  NextBeat: %s", openaiPlan.NextBeat)
	t.Logf("  NextRole: %s", openaiPlan.NextRole)
	t.Logf("  Notes: %s", openaiPlan.Notes)
	t.Logf("")
	t.Logf("Claude (3.5-Sonnet):")
	t.Logf("  FlowMode: %s", claudePlan.FlowMode)
	t.Logf("  UserMindState: %v", claudePlan.UserMindState)
	t.Logf("  NextBeat: %s", claudePlan.NextBeat)
	t.Logf("  NextRole: %s", claudePlan.NextRole)
	t.Logf("  Notes: %s", claudePlan.Notes)
	t.Logf("")

	// éªŒè¯ä¸¤ä¸ªå†³ç­–éƒ½æ˜¯æœ‰æ•ˆçš„
	if openaiPlan.NextBeat == "" || claudePlan.NextBeat == "" {
		t.Error("âŒ Both decisions should have valid next_beat")
	}

	t.Logf("âœ… Both LLMs produced valid decisions")
}
