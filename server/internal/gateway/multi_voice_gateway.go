package gateway

import (
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"log"
	"sync"
	"time"

	"bubble-talk/server/internal/tool"

	"github.com/gorilla/websocket"
)

// MultiVoiceGateway æ˜¯æ”¯æŒå¤šéŸ³è‰²çš„è¯­éŸ³ç½‘å…³
// æ ¸å¿ƒæ¶æ„ï¼š
//  1. æ¯ä¸ªè§’è‰²ä¸€ä¸ªç‹¬ç«‹çš„ Realtime è¿æ¥ï¼ˆvoice å›ºå®šï¼‰ï¼šè´Ÿè´£è¯¥è§’è‰²çš„è¯­éŸ³åˆæˆï¼ˆTTSï¼‰å’Œå¯¹è¯é€»è¾‘ã€‚
//  2. ä¸€ä¸ª ASR ä¸“ç”¨è¿æ¥ï¼ˆåªåšè¯­éŸ³è¯†åˆ«ï¼‰ï¼šè´Ÿè´£æ¥æ”¶ç”¨æˆ·çš„éŸ³é¢‘æµï¼Œè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰ã€‚
//     è¿™ä¸ªè¿æ¥é€šå¸¸é…ç½®ä¸ºä¸ç”ŸæˆéŸ³é¢‘ï¼Œæˆ–è€…ç”Ÿæˆçš„éŸ³é¢‘è¢«ä¸¢å¼ƒã€‚
//  3. é€šè¿‡"æ–‡æœ¬é•œåƒ"è®©æ‰€æœ‰è¿æ¥å…±äº«å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
//     - å½“ ASR è¯†åˆ«åˆ°ç”¨æˆ·è¯´è¯æ—¶ï¼Œå°†æ–‡æœ¬ä½œä¸º Text Item æ³¨å…¥åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ã€‚
//     - å½“æŸä¸ªè§’è‰²è¯´è¯æ—¶ï¼Œå°†å…¶å›å¤æ–‡æœ¬ä½œä¸º Assistant Item æ³¨å…¥åˆ°å…¶ä»–è§’è‰²è¿æ¥ã€‚
//     è¿™æ ·æ‰€æœ‰è¿æ¥éƒ½èƒ½ç»´æŠ¤å®Œæ•´çš„å¯¹è¯å†å²ã€‚
type MultiVoiceGateway struct {
	sessionID string

	// å®¢æˆ·ç«¯è¿æ¥ï¼šä¸å‰ç«¯ï¼ˆWeb/Appï¼‰çš„ WebSocket è¿æ¥ï¼Œä¼ è¾“éŸ³é¢‘æµå’Œæ§åˆ¶æŒ‡ä»¤
	clientConn     *websocket.Conn
	clientConnLock sync.Mutex

	// éŸ³è‰²æ± ï¼ˆç®¡ç†å¤šä¸ªè§’è‰²è¿æ¥ï¼‰ï¼šå°è£…äº†ä¸ OpenAI Realtime API çš„å¤šä¸ªè¿æ¥
	voicePool *VoicePool

	// äº‹ä»¶å¤„ç†å™¨ï¼ˆç”± Orchestrator æ³¨å…¥ï¼‰ï¼šç”¨äºå°†ç½‘å…³æ”¶åˆ°çš„ä¸šåŠ¡äº‹ä»¶ï¼ˆå¦‚ç”¨æˆ·è¯´è¯ã€æ’è¯ã€é€€å‡ºç­‰ï¼‰è½¬å‘ç»™ç¼–æ’å™¨
	eventHandler EventHandler

	// äº‹ä»¶é˜Ÿåˆ—ï¼šä¸²è¡Œå¤„ç†äº‹ä»¶ï¼Œé˜²æ­¢å¹¶å‘ä¿®æ”¹ SessionState
	eventQueue *EventQueue

	// å·¥å…·æ³¨å†Œè¡¨ï¼ˆæ”¯æŒfunction callingï¼‰ï¼šæ‰€æœ‰è§’è‰²å…±äº«çš„å·¥å…·é›†
	toolRegistry *tool.ToolRegistry

	// å“åº”å…ƒæ•°æ®æ³¨å†Œè¡¨ï¼ˆè§£å†³éŸ³é¢‘ä¸å…ƒæ•°æ®å…³è”é—®é¢˜ï¼‰
	metadataRegistry *ResponseMetadataRegistry

	// çŠ¶æ€ç®¡ç†
	ctx       context.Context
	cancel    context.CancelFunc
	closeOnce sync.Once
	closeChan chan struct{}

	// ASR äº‹ä»¶æºé…ç½®ï¼šè§£å†³"åŒç»ˆæ€äº‹ä»¶æº"é—®é¢˜
	// true: åªä½¿ç”¨ conversation.item.input_audio_transcription.completed
	// false: åªä½¿ç”¨ response.done/response.audio_transcript.done
	useTranscriptionCompleted bool

	// å½“å‰å“åº”çš„å…ƒæ•°æ®ï¼ˆè§’è‰²ã€Beatç­‰ï¼‰ï¼šè®°å½•å½“å‰æ­£åœ¨è¯´è¯çš„è§’è‰²å’Œå¯¹åº”çš„å‰§æƒ…èŠ‚æ‹ä¿¡æ¯
	activeMetadata     map[string]interface{}
	activeMetadataLock sync.RWMutex

	// ASR å»é‡ï¼ˆé¿å… response.done ä¸ response.audio_transcript.done é‡å¤è§¦å‘ï¼‰
	// OpenAI Realtime API å¯èƒ½ä¼šé€šè¿‡å¤šç§äº‹ä»¶è¿”å›è½¬å†™ç»“æœï¼Œæˆ‘ä»¬éœ€è¦å»é‡ä»¥é¿å…é‡å¤å¤„ç†
	asrDedupMu          sync.Mutex
	lastASRResponseID   string
	lastASRTranscript   string
	lastASRTranscriptAt time.Time

	// åºåˆ—å·ç”Ÿæˆå™¨ï¼ˆç”¨äº ServerMessageï¼‰ï¼šä¿è¯å‘é€ç»™å®¢æˆ·ç«¯çš„æ¶ˆæ¯æœ‰åº
	seqCounter int64
	seqLock    sync.Mutex

	// é…ç½®
	config GatewayConfig

	// æ—¥å¿—
	logger *log.Logger
}

// NewMultiVoiceGateway åˆ›å»ºä¸€ä¸ªæ”¯æŒå¤šéŸ³è‰²çš„ç½‘å…³
func NewMultiVoiceGateway(sessionID string, clientConn *websocket.Conn, config GatewayConfig) *MultiVoiceGateway {
	ctx, cancel := context.WithCancel(context.Background())

	logger := log.Default()
	g := &MultiVoiceGateway{
		sessionID:  sessionID,
		clientConn: clientConn,
		ctx:        ctx,
		cancel:     cancel,
		closeChan:  make(chan struct{}),
		config:     config,
		logger:     logger,
		// é»˜è®¤ä½¿ç”¨ transcription.completed ä½œä¸ºå”¯ä¸€ ASR äº‹ä»¶æº
		useTranscriptionCompleted: true,
		// åˆå§‹åŒ–å…ƒæ•°æ®æ³¨å†Œè¡¨
		metadataRegistry: NewResponseMetadataRegistry(logger),
	}

	return g
}

// SetEventHandler è®¾ç½®äº‹ä»¶å¤„ç†å™¨ï¼ˆOrchestrator æ³¨å…¥ï¼‰
func (g *MultiVoiceGateway) SetEventHandler(handler EventHandler) {
	g.eventHandler = handler
	// åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—ï¼Œç¡®ä¿äº‹ä»¶ä¸²è¡Œå¤„ç†
	if g.eventQueue == nil {
		g.eventQueue = NewEventQueue(g.sessionID, handler, g.logger)
		g.logger.Printf("[MultiVoiceGateway] Event queue created for session %s", g.sessionID)
	}
}

// SetToolRegistry è®¾ç½®å·¥å…·æ³¨å†Œè¡¨
func (g *MultiVoiceGateway) SetToolRegistry(registry *tool.ToolRegistry) {
	g.toolRegistry = registry
	// å¦‚æœéŸ³è‰²æ± å·²ç»åˆå§‹åŒ–ï¼Œä¼ é€’ç»™æ‰€æœ‰è§’è‰²è¿æ¥
	if g.voicePool != nil {
		g.voicePool.SetToolRegistry(registry)
	}
}

// Start å¯åŠ¨ç½‘å…³
func (g *MultiVoiceGateway) Start(ctx context.Context) error {
	g.logger.Printf("[MultiVoiceGateway] Starting gateway for session %s", g.sessionID)

	if g.clientConn == nil {
		return fmt.Errorf("clientConn is nil")
	}

	// 1. åˆ›å»ºéŸ³è‰²æ± 
	g.logger.Printf("[MultiVoiceGateway] Creating voice pool...")
	roleVoices := make(map[string]string)
	for role, profile := range g.config.RoleProfiles {
		roleVoices[role] = profile.Voice
		g.logger.Printf("[MultiVoiceGateway] Role %s -> Voice %s", role, profile.Voice)
	}

	poolConfig := VoicePoolConfig{
		OpenAIAPIKey:                 g.config.OpenAIAPIKey,
		Model:                        g.config.Model,
		DefaultInstructions:          g.config.DefaultInstructions,
		InputAudioFormat:             g.config.InputAudioFormat,
		OutputAudioFormat:            g.config.OutputAudioFormat,
		InputAudioTranscriptionModel: g.config.InputAudioTranscriptionModel,
		RoleVoices:                   roleVoices,
	}

	g.voicePool = NewVoicePool(g.sessionID, poolConfig)

	// ä¼ é€’å·¥å…·æ³¨å†Œè¡¨åˆ°éŸ³è‰²æ± ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
	if g.toolRegistry != nil {
		g.voicePool.SetToolRegistry(g.toolRegistry)
		g.logger.Printf("[MultiVoiceGateway] Tool registry passed to voice pool")
	}

	// 2. åˆå§‹åŒ–éŸ³è‰²æ± ï¼ˆåˆ›å»ºæ‰€æœ‰ RoleConn å’Œ ASRConnï¼‰
	g.logger.Printf("[MultiVoiceGateway] Initializing voice pool...")
	if err := g.voicePool.Initialize(ctx); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to initialize voice pool: %v", err)
		return fmt.Errorf("initialize voice pool: %w", err)
	}
	g.logger.Printf("[MultiVoiceGateway] âœ… Voice pool initialized")

	// 3. å¯åŠ¨äº‹ä»¶å¾ªç¯
	g.logger.Printf("[MultiVoiceGateway] Starting event loops...")
	go g.clientReadLoop()
	go g.asrReadLoop()
	go g.roleConnsReadLoop()

	g.logger.Printf("[MultiVoiceGateway] âœ… Gateway fully started for session %s", g.sessionID)
	return nil
}

// clientReadLoop ä»å®¢æˆ·ç«¯è¯»å–æ¶ˆæ¯ï¼ˆäº‹ä»¶+éŸ³é¢‘ï¼‰
func (g *MultiVoiceGateway) clientReadLoop() {
	defer g.Close()

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := g.clientConn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] client read error: %v", err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			// JSON äº‹ä»¶
			if err := g.handleClientEvent(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle client event error: %v", err)
				g.sendErrorToClient(err.Error())
			}
		} else if messageType == websocket.BinaryMessage {
			// éŸ³é¢‘æ•°æ®ï¼ˆå‘é€åˆ° ASR è¿æ¥ï¼‰
			if err := g.handleClientAudio(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle client audio error: %v", err)
			}
		}
	}
}

// handleClientEvent å¤„ç†å®¢æˆ·ç«¯ JSON äº‹ä»¶
func (g *MultiVoiceGateway) handleClientEvent(data []byte) error {
	var msg ClientMessage
	if err := json.Unmarshal(data, &msg); err != nil {
		return fmt.Errorf("unmarshal client message: %w", err)
	}

	if msg.ClientTS.IsZero() {
		msg.ClientTS = time.Now()
	}

	g.logger.Printf("[MultiVoiceGateway] client event: type=%s event_id=%s", msg.Type, msg.EventID)

	switch msg.Type {
	case EventTypeBargeIn:
		return g.handleBargeIn(&msg)
	case EventTypeExitRequested, EventTypeQuizAnswer:
		return g.forwardToOrchestrator(&msg)
	default:
		return g.forwardToOrchestrator(&msg)
	}
}

// handleClientAudio å¤„ç†å®¢æˆ·ç«¯éŸ³é¢‘æ•°æ®ï¼ˆå‘é€åˆ° ASR è¿æ¥ï¼‰
func (g *MultiVoiceGateway) handleClientAudio(audioData []byte) error {
	// å°†éŸ³é¢‘æ•°æ®è½¬å‘åˆ° ASR è¿æ¥
	asrConn, err := g.voicePool.GetASRConn()
	if err != nil {
		return fmt.Errorf("get ASR conn: %w", err)
	}

	encoded := base64.StdEncoding.EncodeToString(audioData)
	append := RealtimeInputAudioBufferAppend{
		Type:  "input_audio_buffer.append",
		Audio: encoded,
	}

	return asrConn.SendMessage(append)
}

// handleBargeIn å¤„ç†æ’è¯ä¸­æ–­
func (g *MultiVoiceGateway) handleBargeIn(msg *ClientMessage) error {
	g.logger.Printf("[MultiVoiceGateway] barge-in detected, canceling active response")

	// å–æ¶ˆå½“å‰æ­£åœ¨è¯´è¯çš„è§’è‰²çš„å“åº”
	if err := g.voicePool.CancelCurrentResponse(); err != nil {
		g.logger.Printf("[MultiVoiceGateway] failed to cancel response: %v", err)
	}

	// é€šçŸ¥å®¢æˆ·ç«¯æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
	g.sendToClient(&ServerMessage{
		Type:     EventTypeTTSInterrupted,
		ServerTS: time.Now(),
	})

	// è½¬å‘ç»™ Orchestrator
	return g.forwardToOrchestrator(msg)
}

// forwardToOrchestrator è½¬å‘äº‹ä»¶ç»™ Orchestrator
// ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨äº‹ä»¶é˜Ÿåˆ—ä¸²è¡Œå¤„ç†ï¼Œé˜²æ­¢ SessionState å¹¶å‘ä¿®æ”¹
func (g *MultiVoiceGateway) forwardToOrchestrator(msg *ClientMessage) error {
	if g.eventHandler == nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  no event handler set, dropping event: %s", msg.Type)
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] Forwarding event to Orchestrator: type=%s text=%s", msg.Type, msg.Text)

	// ä½¿ç”¨äº‹ä»¶é˜Ÿåˆ—ä»£æ›¿ç›´æ¥çš„ goroutineï¼Œä¿è¯ï¼š
	// 1. åŒä¸€ session çš„æ‰€æœ‰äº‹ä»¶ä¸²è¡Œå¤„ç†ï¼ˆé˜²æ­¢å¹¶å‘å†™ SessionStateï¼‰
	// 2. äº‹ä»¶æŒ‰æ¥æ”¶é¡ºåºå¤„ç†ï¼ˆé˜²æ­¢ asr_final å’Œ assistant_text ä¹±åºï¼‰
	if g.eventQueue != nil {
		if err := g.eventQueue.Enqueue(msg); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âŒ Failed to enqueue event: %v", err)
			g.sendErrorToClient(fmt.Sprintf("Event queue error: %v", err))
			return err
		}
		return nil
	}

	// é™çº§æ–¹æ¡ˆï¼šå¦‚æœäº‹ä»¶é˜Ÿåˆ—æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŒæ­¥å¤„ç†ï¼ˆä¸å†ä½¿ç”¨ goroutineï¼‰
	// è¿™æ ·è™½ç„¶å¯èƒ½é˜»å¡ï¼Œä½†è‡³å°‘ä¸ä¼šå‡ºç°å¹¶å‘é—®é¢˜
	g.logger.Printf("[MultiVoiceGateway] âš ï¸  Event queue not initialized, using synchronous processing")
	ctx, cancel := context.WithTimeout(g.ctx, 10*time.Second)
	defer cancel()

	if err := g.eventHandler(ctx, msg); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Orchestrator handler error: %v", err)
		g.sendErrorToClient(fmt.Sprintf("Orchestrator error: %v", err))
		return err
	}

	g.logger.Printf("[MultiVoiceGateway] âœ… Orchestrator handled event successfully")
	return nil
}

// asrReadLoop ä» ASR è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) asrReadLoop() {
	asrConn, err := g.voicePool.GetASRConn()
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to get ASR conn: %v", err)
		return
	}

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := asrConn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] ASR read error: %v", err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			if err := g.handleASREvent(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle ASR event error: %v", err)
			}
		}
	}
}

// handleASREvent å¤„ç† ASR è¿æ¥çš„äº‹ä»¶
// ASR è¿æ¥çš„ä¸»è¦èŒè´£æ˜¯æ¥æ”¶ç”¨æˆ·éŸ³é¢‘å¹¶è½¬å†™ä¸ºæ–‡æœ¬ï¼Œå®ƒä¸åº”è¯¥ç”ŸæˆéŸ³é¢‘å“åº”ã€‚
// ä½†ç”±äº OpenAI Realtime API çš„æœºåˆ¶ï¼ŒVAD è§¦å‘æ—¶å¯èƒ½ä¼šè‡ªåŠ¨åˆ›å»º responseã€‚
// æˆ‘ä»¬éœ€è¦å¤„ç†è¿™äº›äº‹ä»¶ï¼Œæå–è½¬å†™æ–‡æœ¬ï¼Œå¹¶ç¡®ä¿ä¸ä¼šäº§ç”Ÿä¸éœ€è¦çš„éŸ³é¢‘è¾“å‡ºã€‚
func (g *MultiVoiceGateway) handleASREvent(data []byte) error {
	var event map[string]interface{}
	if err := json.Unmarshal(data, &event); err != nil {
		return fmt.Errorf("unmarshal ASR event: %w", err)
	}

	eventType, _ := event["type"].(string)
	g.logger.Printf("[MultiVoiceGateway] ASR event: %s", eventType)

	switch eventType {
	case "error":
		// è®°å½• API é”™è¯¯
		g.logRealtimeError("ASR", event)
		return nil

	// ASR ç›¸å…³äº‹ä»¶
	case "input_audio_buffer.speech_started":
		// VAD æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯
		// ä¿®å¤æ–¹æ¡ˆï¼šæœåŠ¡ç«¯å…œåº•çš„æ’è¯æ£€æµ‹
		g.logger.Printf("[MultiVoiceGateway] ğŸ¤ User started speaking (server-side VAD)")

		// æœåŠ¡ç«¯å…œåº•ï¼šå¦‚æœæœ‰è§’è‰²æ­£åœ¨è¯´è¯ï¼Œç«‹å³å–æ¶ˆ
		// è¿™æ˜¯å¯¹å®¢æˆ·ç«¯ barge_in çš„è¡¥å……ï¼Œé˜²æ­¢å®¢æˆ·ç«¯å»¶è¿Ÿæˆ–æœªå‘é€ barge_in
		if err := g.voicePool.CancelCurrentResponse(); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸  Server-side barge-in cancel failed: %v", err)
		} else {
			g.logger.Printf("[MultiVoiceGateway] âœ… Server-side barge-in: cancelled current response")
		}

		return nil

	case "input_audio_buffer.speech_stopped":
		// VAD æ£€æµ‹åˆ°ç”¨æˆ·åœæ­¢è¯´è¯
		// æ³¨æ„ä¸ç­‰åŒäºç”¨æˆ·çœŸçš„è¯´å®Œäº†ï¼Œå¯èƒ½åªæ˜¯çŸ­æš‚åœé¡¿ã€VAD é™éŸ³é˜ˆå€¼è§¦å‘
		g.logger.Printf("[MultiVoiceGateway] User stopped speaking")
		return nil

	case "conversation.item.input_audio_transcription.completed":
		// ASR å·²å®Œæˆï¼ŒæœåŠ¡å™¨ç”Ÿæˆäº†"æœ€ç»ˆå¯ç”¨çš„ç”¨æˆ·è¯­éŸ³æ–‡æœ¬"ï¼Œç”¨æˆ·"è¯´äº†ä»€ä¹ˆ"åœ¨è¿™ä¸€åˆ»æ‰ç¡®å®š
		// å½“ session é…ç½®äº† input_audio_transcription æ—¶è§¦å‘
		// ä¿®å¤æ–¹æ¡ˆï¼šè¿™æ˜¯ ASR çš„å”¯ä¸€çœŸç›¸æ¥æºï¼ˆå¦‚æœ useTranscriptionCompleted=trueï¼‰
		if g.useTranscriptionCompleted {
			return g.handleASRTranscriptionCompleted(event)
		}
		g.logger.Printf("[MultiVoiceGateway] Ignoring transcription.completed (using response.done as ASR source)")
		return nil

	// response ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
	case "response.created":
		// ä¸€ä¸ªæ–°çš„ response ç”Ÿå‘½å‘¨æœŸè¢«åˆ›å»ºäº†
		// ASR è¿æ¥ä¸åº”è¯¥åˆ›å»º responseï¼Œä½†ç”±äº API é»˜è®¤è¡Œä¸ºï¼ˆVAD è§¦å‘ responseï¼‰ï¼Œå®ƒå¯èƒ½ä¼šåˆ›å»ºã€‚
		// æˆ‘ä»¬éœ€è¦è®°å½•è¿™ä¸ª response IDï¼Œä»¥ä¾¿åç»­æå–è½¬å†™æˆ–å–æ¶ˆå®ƒã€‚
		// å…³é”®ç‚¹ï¼šASR è¿æ¥çš„ instructions é€šå¸¸è®¾ç½®ä¸ºç©ºæˆ–"åªåšè½¬å†™"ï¼Œä»¥å‡å°‘æ¨¡å‹ç”Ÿæˆå†…å®¹çš„æ¶ˆè€—ã€‚
		responseID, _ := event["response"].(map[string]interface{})["id"].(string)
		if responseID != "" {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸ ASR created response %s (will extract transcription and cancel)", responseID)
			asrConn, _ := g.voicePool.GetASRConn()
			if asrConn != nil {
				asrConn.SetActiveResponse(responseID)
			}
		}

	case "response.audio_transcript.delta":
		// assistant è¯­éŸ³è¾“å‡ºå¯¹åº”çš„â€œè½¬å†™æ–‡æœ¬ï¼ˆå®æ—¶ï¼‰â€çš„å¢é‡
		// å¿½ç•¥ ASR çš„éŸ³é¢‘è½¬å†™å¢é‡ï¼ˆæˆ‘ä»¬åªå…³å¿ƒæœ€ç»ˆæ–‡æœ¬ï¼Œé¿å…é¢‘ç¹åˆ·æ–° UI æˆ–é€»è¾‘ï¼‰
		return nil

	case "response.audio_transcript.done", "response.done":
		// assistant è¯­éŸ³è½¬å†™æ–‡æœ¬å·²å®Œæˆï¼Œresponse ç”Ÿå‘½å‘¨æœŸå½»åº•ç»“æŸ
		// ä¿®å¤æ–¹æ¡ˆï¼šåªåœ¨ useTranscriptionCompleted=false æ—¶ä½¿ç”¨è¿™ä¸ªä½œä¸º ASR æº
		if !g.useTranscriptionCompleted {
			return g.handleASRResponseDone(event)
		}

		// å¦‚æœä½¿ç”¨ transcription.completedï¼Œè¿™é‡Œä»ç„¶è¦å–æ¶ˆ ASR responseï¼Œä½†ä¸ä¸ŠæŠ¥æ–‡æœ¬
		g.logger.Printf("[MultiVoiceGateway] ASR response done (will cancel but not report, using transcription.completed as source)")
		asrConn, _ := g.voicePool.GetASRConn()
		if asrConn != nil {
			if err := asrConn.CancelResponse(); err != nil {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel ASR response: %v", err)
			}
		}
		return nil

	}

	return nil
}

// handleASRResponseDone ä» ASR response ä¸­æå–è½¬å†™å¹¶å–æ¶ˆ response
// ç›®çš„ï¼šè·å–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å†…å®¹ï¼ŒåŒæ—¶ç¡®ä¿ ASR è¿æ¥ä¸æ’­æ”¾éŸ³é¢‘ã€‚
func (g *MultiVoiceGateway) handleASRResponseDone(event map[string]interface{}) error {
	// ä» response ä¸­æå–è½¬å†™
	// ç»“æ„å¯èƒ½æ˜¯ response.output[].content[].transcript (response.done)
	// æˆ–è€…æ˜¯ç›´æ¥çš„ transcript å­—æ®µ (response.audio_transcript.done)
	var transcript string
	responseID := ""

	if event["type"] == "response.done" {
		response, _ := event["response"].(map[string]interface{})
		if response != nil {
			responseID, _ = response["id"].(string)
		}
		output, _ := response["output"].([]interface{})

		for _, item := range output {
			itemMap, _ := item.(map[string]interface{})
			itemType, _ := itemMap["type"].(string)
			if itemType == "message" {
				content, _ := itemMap["content"].([]interface{})
				for _, c := range content {
					cMap, _ := c.(map[string]interface{})
					if cMap["type"] == "audio" {
						text, _ := cMap["transcript"].(string)
						transcript += text
					}
				}
			}
		}
	} else {
		// response.audio_transcript.done
		if v, ok := event["response_id"].(string); ok {
			responseID = v
		}
		transcript, _ = event["transcript"].(string)
	}

	if transcript == "" {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸ Empty ASR transcript")
		return nil
	}

	// ASR å»é‡ï¼šé¿å…åŒä¸€ä¸ª response çš„å¤šæ¬¡äº‹ä»¶å¯¼è‡´é‡å¤å¤„ç†
	if g.shouldDropASRResult(responseID, transcript) {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸ Duplicate ASR transcript dropped (response_id=%s)", responseID)
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] ğŸ“ ASR transcription: %s", transcript)

	// å–æ¶ˆ ASR responseï¼ˆæˆ‘ä»¬ä¸éœ€è¦å®ƒçš„éŸ³é¢‘è¾“å‡ºï¼Œé˜²æ­¢å®ƒ"è¯´è¯"ï¼‰
	// è™½ç„¶ response å·²ç» doneï¼Œä½†å–æ¶ˆæ“ä½œå¯ä»¥ç¡®ä¿æ¸…ç†ç›¸å…³çŠ¶æ€
	asrConn, _ := g.voicePool.GetASRConn()
	if asrConn != nil {
		if err := asrConn.CancelResponse(); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel ASR response: %v", err)
		}
	}

	// 1. åŒæ­¥ç”¨æˆ·æ–‡æœ¬åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
	// è¿™æ˜¯å¤šéŸ³è‰²æ¶æ„çš„å…³é”®ï¼šè®©æ‰€æœ‰è§’è‰²éƒ½çŸ¥é“ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œ
	// å³ä½¿å®ƒä»¬ä¸æ˜¯æ¥æ”¶éŸ³é¢‘çš„é‚£ä¸ªè¿æ¥ã€‚
	if err := g.voicePool.SyncUserText(transcript); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync user text: %v", err)
	}

	// 2. è½¬å‘ç»™ Orchestrator å¤„ç†
	// Orchestrator ä¼šæ ¹æ®è¿™ä¸ªæ–‡æœ¬å†³å®šä¸‹ä¸€æ­¥çš„å‰§æƒ…ï¼ˆBeatï¼‰æˆ–è®©å“ªä¸ªè§’è‰²å›ç­”ã€‚
	msg := &ClientMessage{
		Type:     EventTypeASRFinal,
		EventID:  fmt.Sprintf("asr_%d", time.Now().UnixNano()),
		Text:     transcript,
		ClientTS: time.Now(),
	}

	return g.forwardToOrchestrator(msg)
}

// handleASRTranscriptionCompleted å¤„ç†è½¬å†™å®Œæˆäº‹ä»¶
// ä¿®å¤æ–¹æ¡ˆï¼šè¿™æ˜¯ ASR çš„å”¯ä¸€çœŸç›¸æ¥æºï¼ˆå½“ useTranscriptionCompleted=trueï¼‰
// é¿å…ä¸ handleASRResponseDone é‡å¤ä¸ŠæŠ¥åŒä¸€å¥è¯
func (g *MultiVoiceGateway) handleASRTranscriptionCompleted(event map[string]interface{}) error {
	transcript, _ := event["transcript"].(string)
	if transcript == "" {
		g.logger.Printf("[MultiVoiceGateway] Empty transcript, ignoring")
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] âœ… [PRIMARY ASR SOURCE] User transcript: %s", transcript)

	// 1. åŒæ­¥ç”¨æˆ·æ–‡æœ¬åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
	if err := g.voicePool.SyncUserText(transcript); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync user text: %v", err)
	}

	// 2. è½¬å‘ç»™ Orchestrator å¤„ç†
	msg := &ClientMessage{
		Type:     EventTypeASRFinal,
		EventID:  fmt.Sprintf("asr_%d", time.Now().UnixNano()),
		Text:     transcript,
		ClientTS: time.Now(),
	}

	return g.forwardToOrchestrator(msg)
}

// roleConnsReadLoop ä»æ‰€æœ‰è§’è‰²è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) roleConnsReadLoop() {
	// ä¸ºæ¯ä¸ªè§’è‰²è¿æ¥å¯åŠ¨ä¸€ä¸ªè¯»å–åç¨‹
	for role := range g.config.RoleProfiles {
		role := role // æ•è·å¾ªç¯å˜é‡
		go g.roleConnReadLoop(role)
	}
}

// roleConnReadLoop ä»æŒ‡å®šè§’è‰²è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) roleConnReadLoop(role string) {
	conn, err := g.voicePool.GetRoleConn(g.ctx, role)
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to get role conn for %s: %v", role, err)
		return
	}

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := conn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] Role %s read error: %v", role, err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			if err := g.handleRoleConnEvent(role, data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle role conn event error: %v", err)
			}
		}
	}
}

// handleRoleConnEvent å¤„ç†è§’è‰²è¿æ¥çš„äº‹ä»¶
// è§’è‰²è¿æ¥ä¸»è¦è´Ÿè´£ TTSï¼ˆè¯­éŸ³åˆæˆï¼‰å’Œå¯¹è¯é€»è¾‘ã€‚
// æˆ‘ä»¬éœ€è¦ç›‘å¬è¿™äº›äº‹ä»¶æ¥åŒæ­¥çŠ¶æ€ã€è½¬å‘éŸ³é¢‘ç»™å®¢æˆ·ç«¯ï¼Œä»¥åŠè¿›è¡Œæ–‡æœ¬é•œåƒã€‚
func (g *MultiVoiceGateway) handleRoleConnEvent(role string, data []byte) error {
	var event map[string]interface{}
	if err := json.Unmarshal(data, &event); err != nil {
		return fmt.Errorf("unmarshal role conn event: %w", err)
	}

	eventType, _ := event["type"].(string)
	g.logger.Printf("[MultiVoiceGateway] Role %s event: %s", role, eventType)

	switch eventType {
	case "error":
		g.logRealtimeError("Role "+role, event)
		return nil

	case "response.created":
		// å“åº”åˆ›å»º - æ„å‘³ç€è§’è‰²å‡†å¤‡å¼€å§‹è¯´è¯
		// 1. è®°å½• active response IDï¼Œä»¥ä¾¿åœ¨æ’è¯æ—¶èƒ½å–æ¶ˆå®ƒ
		responseID, _ := event["response"].(map[string]interface{})["id"].(string)
		conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
		if conn != nil {
			conn.SetActiveResponse(responseID)

			// 2. æ³¨å†Œå…ƒæ•°æ®ï¼šå°† responseID ä¸ roleã€metadata å…³è”
			if metadata := conn.GetPendingMetadata(); metadata != nil {
				g.metadataRegistry.Register(responseID, role, metadata)
				g.logger.Printf("[MultiVoiceGateway] âœ… Registered metadata for responseID=%s role=%s",
					responseID, role)
			} else {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸  No pending metadata for responseID=%s role=%s",
					responseID, role)
			}
		}

		// 3. å‘é€ tts_started ç»™å‰ç«¯ï¼ŒåŒ…å«è§’è‰²ä¿¡æ¯ï¼Œè®©å‰ç«¯æ˜¾ç¤º"æ­£åœ¨è¯´è¯"çš„åŠ¨ç”»
		g.sendTTSStartedToClient(role)

	case "response.audio.delta":
		// éŸ³é¢‘å¢é‡ - è¿™æ˜¯å®æ—¶çš„è¯­éŸ³æ•°æ®
		// æˆ‘ä»¬ç›´æ¥è½¬å‘ç»™å®¢æˆ·ç«¯æ’­æ”¾
		return g.handleAudioDelta(role, event)

	case "response.audio_transcript.delta":
		// æ–‡æœ¬å¢é‡ - å®æ—¶å­—å¹•
		// ç›®å‰åªæ‰“å°æ—¥å¿—ï¼Œå¦‚æœå‰ç«¯éœ€è¦å®æ—¶é€å­—æ˜¾ç¤ºï¼Œå¯ä»¥è½¬å‘è¿™ä¸ªäº‹ä»¶
		delta, _ := event["delta"].(string)
		g.logger.Printf("[MultiVoiceGateway] Role %s transcript delta: %s", role, delta)

	case "response.done":
		// å“åº”å®Œæˆ - è§’è‰²è¯´å®Œäº†ä¸€å¥è¯
		// 1. é€šçŸ¥å‰ç«¯ TTS ç»“æŸ
		g.sendTTSCompletedToClient(role)
		// 2. æå–å®Œæ•´æ–‡æœ¬ï¼Œè¿›è¡Œæ–‡æœ¬é•œåƒï¼ˆåŒæ­¥ç»™å…¶ä»–è§’è‰²ï¼‰å’Œä¸šåŠ¡å¤„ç†
		return g.handleResponseDone(role, event)

	case "response.cancelled":
		// å“åº”è¢«å–æ¶ˆ - æ’è¯ä¸­æ–­æˆåŠŸ
		// ä¿®å¤æ–¹æ¡ˆï¼šå¤„ç†å–æ¶ˆåçš„çŠ¶æ€æ”¶æ•›
		g.logger.Printf("[MultiVoiceGateway] âœ… Role %s response cancelled (barge-in successful)", role)

		// æå– responseID
		response, _ := event["response"].(map[string]interface{})
		responseID, _ := response["id"].(string)

		// 1. æ¸…é™¤æ´»è·ƒå“åº”
		conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
		if conn != nil {
			conn.ClearActiveResponse()
		}

		// 2. æ¸…é™¤æ­£åœ¨è¯´è¯çš„è§’è‰²
		g.voicePool.ClearSpeakingRole()

		// 3. æ³¨é”€å…ƒæ•°æ®
		if responseID != "" {
			g.metadataRegistry.Unregister(responseID)
			g.logger.Printf("[MultiVoiceGateway] âœ… Unregistered metadata for cancelled responseID=%s", responseID)
		}

		// 4. é€šçŸ¥å‰ç«¯ TTS å·²ä¸­æ–­
		g.sendTTSCompletedToClient(role)

		return nil
	}

	return nil
}

const asrDuplicateWindow = 2 * time.Second

// shouldDropASRResult ç”¨äºå»é‡ ASR çš„é‡å¤å®Œæˆäº‹ä»¶ã€‚
//
// è¯´æ˜ï¼ˆä¸­æ–‡ï¼‰ï¼š
// è¿™ä¸ªå‡½æ•°ç”¨äºé¿å… ASR è¿æ¥é‡å¤è§¦å‘åŒä¸€æ¡æœ€ç»ˆè½¬å†™ï¼ˆcompletionï¼‰å¯¼è‡´çš„é‡å¤ä¸ŠæŠ¥ã€‚
// ASR åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¹åŒä¸€æ®µè¯­éŸ³æ—¢äº§ç”Ÿ response.doneï¼ˆå®Œæ•´ response åŒ…å« outputï¼‰
// åˆäº§ç”Ÿ response.audio_transcript.doneï¼ˆå•ç‹¬çš„è½¬å†™å®Œæˆäº‹ä»¶ï¼‰ï¼Œæˆ–è€…å®¢æˆ·ç«¯/æœåŠ¡ç«¯åœ¨çŸ­æ—¶é—´å†…
// æ”¶åˆ°åŒæ ·çš„è½¬å†™ä¸¤æ¬¡ã€‚å› æ­¤éœ€è¦ç®€å•çš„å»é‡ç­–ç•¥æ¥é¿å…ä¸Šå±‚ï¼ˆæ¯”å¦‚ Orchestratorï¼‰é‡å¤å¤„ç†ç›¸åŒçš„æ–‡æœ¬ã€‚
//
// å»é‡ç­–ç•¥ï¼š
// 1) ä¼˜å…ˆåŸºäº responseID å»é‡ï¼š
//   - å¦‚æœæœ¬æ¬¡äº‹ä»¶åŒ…å«éç©ºçš„ responseIDï¼Œä¸”ä¸ä¸Šä¸€æ¬¡è®°å½•çš„ lastASRResponseID ç›¸åŒï¼Œ
//     åˆ™è®¤ä¸ºæ˜¯åŒä¸€æ¬¡ response çš„é‡å¤å®Œæˆäº‹ä»¶ï¼Œç›´æ¥è¿”å› trueï¼ˆä¸¢å¼ƒï¼‰ã€‚
//   - å¦åˆ™å°† lastASRResponseID æ›´æ–°ä¸ºå½“å‰ responseIDï¼ŒåŒæ—¶æ›´æ–° lastASRTranscript/lastASRTranscriptAt
//     ä¸ºå½“å‰ transcript ä¸æ—¶é—´ï¼Œå¹¶è¿”å› falseï¼ˆä¸ä¸¢å¼ƒï¼‰ã€‚
//     è¯´æ˜ï¼šresponseID æ˜¯æœ€å¯é çš„å»é‡é”®ï¼Œå› ä¸ºåŒä¸€ä¸ª response çš„ä¸åŒå®Œæˆäº‹ä»¶ï¼ˆä¾‹å¦‚ audio_transcript.done
//     ä¸ response.doneï¼‰é€šå¸¸ä¼šå¸¦ç›¸åŒçš„ response idã€‚
//
// 2) å½“ responseID ä¸å¯ç”¨æ—¶ï¼Œå›é€€åˆ°åŸºäº transcript å†…å®¹çš„æ—¶é—´çª—å£å»é‡ï¼š
//   - å¦‚æœæœ¬æ¬¡äº‹ä»¶çš„ transcript ä¸ä¸Šä¸€æ¬¡è®°å½•çš„ lastASRTranscript å®Œå…¨ç›¸åŒï¼Œä¸”è·ç¦»ä¸Šæ¬¡è®°å½•æ—¶é—´
//     lastASRTranscriptAt ä¸è¶…è¿‡ asrDuplicateWindowï¼ˆ2 ç§’ï¼‰ï¼Œåˆ™è®¤ä¸ºæ˜¯é‡å¤è½¬å†™ï¼Œè¿”å› trueï¼ˆä¸¢å¼ƒï¼‰ã€‚
//   - å¦åˆ™å°† lastASRTranscript ä¸ lastASRTranscriptAt æ›´æ–°ä¸ºå½“å‰å€¼å¹¶è¿”å› falseï¼ˆä¸ä¸¢å¼ƒï¼‰ã€‚
//
// äº’æ–¥ä¸å¹¶å‘ï¼š
//   - å‡½æ•°å†…éƒ¨ä½¿ç”¨ g.asrDedupMu ä¿æŠ¤å¯¹ lastASRResponseID/lastASRTranscript/lastASRTranscriptAt çš„è¯»å†™ï¼Œ
//     ç¡®ä¿åœ¨å¹¶å‘ ASR äº‹ä»¶åˆ°è¾¾æ—¶ä¸ä¼šå‘ç”Ÿç«æ€æ¡ä»¶ã€‚
//
// è®¾è®¡è€ƒé‡ä¸ä¾‹å­ï¼š
//   - å¸¸è§æƒ…å†µ Aï¼šASR å…ˆå‘é€ response.audio_transcript.doneï¼ˆå« response_idï¼‰ï¼Œéšåå‘é€ response.doneã€‚
//     ä¸¤ä¸ªäº‹ä»¶ä¼šæºå¸¦ç›¸åŒçš„ responseIDï¼ŒåŸºäº responseID çš„å»é‡å¯ä»¥ç›´æ¥è¯†åˆ«å¹¶ä¸¢å¼ƒç¬¬äºŒæ¬¡ã€‚
//   - å¸¸è§æƒ…å†µ Bï¼šæŸäº› ASR å›è°ƒåªåŒ…å« transcript è€Œæ²¡æœ‰ responseIDï¼ˆæˆ– responseID ä¸ºç©ºï¼‰ï¼Œ
//     æ­¤æ—¶ä½¿ç”¨ transcript + æ—¶é—´çª—å£ï¼ˆ2sï¼‰å»é‡èƒ½åœ¨çŸ­æ—¶é—´å†…åˆå¹¶é‡å¤ä¸ŠæŠ¥ï¼Œä½†ä¸ä¼šæ— é™æœŸä¸¢å¼ƒ
//     ä¸å†å²å¾ˆæ—©ä¹‹å‰ç›¸åŒçš„æ–‡æœ¬ã€‚
//   - ä¸ºä»€ä¹ˆä½¿ç”¨æ—¶é—´çª—å£ï¼šçº¯æ–‡æœ¬åŒ¹é…å®¹æ˜“è¯¯åˆ¤ï¼ˆä¸åŒæ—¶é—´çš„ç›¸åŒçŸ­è¯­å¯èƒ½æ˜¯åˆæ³•çš„æ–°è¾“å…¥ï¼‰ï¼Œ
//     å› æ­¤é™åˆ¶åœ¨çŸ­æ—¶é—´çª—å£å†…æ‰è®¤ä¸ºæ˜¯é‡å¤ã€‚
//
// æ³¨æ„ï¼šè¯¥å‡½æ•°åªè´Ÿè´£å†³å®šæ˜¯å¦ä¸¢å¼ƒäº‹ä»¶ï¼›ä¸Šå±‚åœ¨é‡åˆ°ç©º transcript æ—¶å·²æå‰å¿½ç•¥ï¼Œå› æ­¤è¿™é‡Œä¸éœ€è¦
// å¯¹ç©ºæ–‡æœ¬åšé¢å¤–åˆ¤æ–­ï¼ˆä½†ä¿æŒè¦†ç›–æ€§ï¼Œå½“å‰å®ç°ä¹Ÿä¼šæ­£ç¡®å¤„ç†ç©º transcriptï¼‰ã€‚
func (g *MultiVoiceGateway) shouldDropASRResult(responseID string, transcript string) bool {
	g.asrDedupMu.Lock()
	defer g.asrDedupMu.Unlock()

	if responseID != "" {
		if responseID == g.lastASRResponseID {
			return true
		}
		g.lastASRResponseID = responseID
		g.lastASRTranscript = transcript
		g.lastASRTranscriptAt = time.Now()
		return false
	}

	if transcript != "" && transcript == g.lastASRTranscript {
		if time.Since(g.lastASRTranscriptAt) <= asrDuplicateWindow {
			return true
		}
	}

	g.lastASRTranscript = transcript
	g.lastASRTranscriptAt = time.Now()
	return false
}

func (g *MultiVoiceGateway) logRealtimeError(scope string, event map[string]interface{}) {
	raw, err := json.Marshal(event)
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] %s error payload marshal failed: %v", scope, err)
		return
	}

	g.logger.Printf("[MultiVoiceGateway] %s error payload: %s", scope, string(raw))

	if errObj, ok := event["error"].(map[string]interface{}); ok {
		g.logger.Printf("[MultiVoiceGateway] %s error detail: type=%v code=%v message=%v",
			scope,
			errObj["type"],
			errObj["code"],
			errObj["message"],
		)
	}
}

// handleAudioDelta å¤„ç†éŸ³é¢‘å¢é‡
func (g *MultiVoiceGateway) handleAudioDelta(role string, event map[string]interface{}) error {
	delta, _ := event["delta"].(string)
	if delta == "" {
		return nil
	}

	// è§£ç  Base64
	audioData, err := base64.StdEncoding.DecodeString(delta)
	if err != nil {
		return fmt.Errorf("decode audio delta: %w", err)
	}

	// è½¬å‘ç»™å®¢æˆ·ç«¯ï¼ˆä½œä¸ºäºŒè¿›åˆ¶æ¶ˆæ¯ï¼‰
	g.clientConnLock.Lock()
	defer g.clientConnLock.Unlock()

	if err := g.clientConn.WriteMessage(websocket.BinaryMessage, audioData); err != nil {
		return fmt.Errorf("write audio to client: %w", err)
	}

	return nil
}

// handleResponseDone å¤„ç†å“åº”å®Œæˆäº‹ä»¶
func (g *MultiVoiceGateway) handleResponseDone(role string, event map[string]interface{}) error {
	g.logger.Printf("[MultiVoiceGateway] Role %s response done", role)

	// æå– responseID
	response, _ := event["response"].(map[string]interface{})
	responseID, _ := response["id"].(string)

	// æ¸…é™¤æ´»è·ƒå“åº”
	conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
	if conn != nil {
		conn.ClearActiveResponse()
	}

	// æ¸…é™¤æ­£åœ¨è¯´è¯çš„è§’è‰²
	g.voicePool.ClearSpeakingRole()

	// æ³¨é”€å…ƒæ•°æ®
	if responseID != "" {
		g.metadataRegistry.Unregister(responseID)
		g.logger.Printf("[MultiVoiceGateway] âœ… Unregistered metadata for responseID=%s", responseID)
	}

	// æå–æœ€ç»ˆæ–‡æœ¬
	output, _ := response["output"].([]interface{})

	var finalText string
	for _, item := range output {
		itemMap, _ := item.(map[string]interface{})
		itemType, _ := itemMap["type"].(string)
		if itemType == "message" {
			content, _ := itemMap["content"].([]interface{})
			for _, c := range content {
				cMap, _ := c.(map[string]interface{})
				if cMap["type"] == "text" {
					text, _ := cMap["text"].(string)
					finalText += text
				} else if cMap["type"] == "audio" {
					transcript, _ := cMap["transcript"].(string)
					finalText += transcript
				}
			}
		}
	}

	if finalText != "" {
		g.logger.Printf("[MultiVoiceGateway] Role %s final text: %s", role, finalText)

		// åŒæ­¥åˆ°æ‰€æœ‰å…¶ä»–è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
		if err := g.voicePool.SyncAssistantText(finalText, role); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync assistant text: %v", err)
		}

		// å°†æœ€ç»ˆæ–‡æœ¬å‘ç»™å‰ç«¯ï¼ˆç”¨äº UI æ°”æ³¡/å­—å¹•ï¼‰å¹¶å›çŒç»™ Orchestratorï¼ˆç”¨äº SessionState å½’çº¦ï¼Œæ”¯æ’‘è§’è‰²è½®è½¬ï¼‰ã€‚
		metadata := g.snapshotActiveMetadata(role)
		_ = g.sendToClient(&ServerMessage{
			Type:     EventTypeAssistantText,
			Text:     finalText,
			Metadata: metadata,
			ServerTS: time.Now(),
		})

		_ = g.forwardToOrchestrator(&ClientMessage{
			Type:     EventTypeAssistantText,
			EventID:  fmt.Sprintf("assistant_%d", time.Now().UnixNano()),
			Text:     finalText,
			Metadata: metadata,
			ClientTS: time.Now(),
		})
	}

	return nil
}

// snapshotActiveMetadata è·å–è§’è‰²çš„æœ€æ–°å“åº”å…ƒæ•°æ®
func (g *MultiVoiceGateway) snapshotActiveMetadata(role string) map[string]interface{} {
	// ä»æ³¨å†Œè¡¨è·å–è¯¥è§’è‰²çš„æœ€æ–°å…ƒæ•°æ®
	if rm, ok := g.metadataRegistry.GetByRole(role); ok {
		metadata := make(map[string]interface{})
		for k, v := range rm.Metadata {
			metadata[k] = v
		}
		// ç¡®ä¿åŒ…å« role
		metadata["role"] = role
		return metadata
	}

	// é™çº§ï¼šå¦‚æœæ³¨å†Œè¡¨ä¸­æ²¡æœ‰ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
	return map[string]interface{}{
		"role": role,
	}
}

// SendInstructions å‘é€æŒ‡ä»¤åˆ°æŒ‡å®šè§’è‰²çš„è¿æ¥
func (g *MultiVoiceGateway) SendInstructions(ctx context.Context, instructions string, metadata map[string]interface{}) error {
	// ä» metadata ä¸­æå–è§’è‰²
	role, ok := metadata["role"].(string)
	if !ok || role == "" {
		g.logger.Printf("[MultiVoiceGateway] âŒ role not specified in metadata: %+v", metadata)
		return fmt.Errorf("role not specified in metadata")
	}

	g.logger.Printf("[MultiVoiceGateway] Sending instructions to role %s (len=%d)", role, len(instructions))
	g.logger.Printf("[MultiVoiceGateway] Metadata: %+v", metadata)

	// ä¿å­˜æ´»è·ƒå…ƒæ•°æ®
	g.activeMetadataLock.Lock()
	g.activeMetadata = metadata
	g.activeMetadataLock.Unlock()

	// åœ¨æŒ‡å®šè§’è‰²çš„è¿æ¥ä¸Šåˆ›å»ºå“åº”
	err := g.voicePool.CreateResponse(ctx, role, instructions, metadata)
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to create response for role %s: %v", role, err)
	}
	return err
}

// sendToClient å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendToClient(msg *ServerMessage) error {
	g.seqLock.Lock()
	g.seqCounter++
	msg.Seq = g.seqCounter
	g.seqLock.Unlock()

	data, err := json.Marshal(msg)
	if err != nil {
		return fmt.Errorf("marshal server message: %w", err)
	}

	g.clientConnLock.Lock()
	defer g.clientConnLock.Unlock()

	return g.clientConn.WriteMessage(websocket.TextMessage, data)
}

// sendErrorToClient å‘é€é”™è¯¯æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendErrorToClient(errMsg string) {
	_ = g.sendToClient(&ServerMessage{
		Type:     "error",
		Error:    errMsg,
		ServerTS: time.Now(),
	})
}

// sendTTSStartedToClient å‘é€ TTS å¼€å§‹äº‹ä»¶ç»™å®¢æˆ·ç«¯ï¼ˆåŒ…å«è§’è‰²ä¿¡æ¯ï¼‰
func (g *MultiVoiceGateway) sendTTSStartedToClient(role string) {
	metadata := g.snapshotActiveMetadata(role)

	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending tts_started to client: role=%s", role)

	_ = g.sendToClient(&ServerMessage{
		Type:     "tts_started",
		Metadata: metadata,
		ServerTS: time.Now(),
	})
}

// sendTTSCompletedToClient å‘é€ TTS å®Œæˆäº‹ä»¶ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendTTSCompletedToClient(role string) {
	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending tts_completed to client: role=%s", role)

	_ = g.sendToClient(&ServerMessage{
		Type: "tts_completed",
		Metadata: map[string]interface{}{
			"role": role,
		},
		ServerTS: time.Now(),
	})
}

// SendQuizToClient å‘é€é€‰æ‹©é¢˜åˆ°å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) SendQuizToClient(quizID, question string, options []string, context string) error {
	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending quiz to client: quiz_id=%s", quizID)

	msg := &ServerMessage{
		Type: EventTypeQuizShow,
		QuizData: &QuizMessageData{
			QuizID:   quizID,
			Question: question,
			Options:  options,
			Context:  context,
		},
		ServerTS: time.Now(),
	}

	return g.sendToClient(msg)
}

// Close å…³é—­ç½‘å…³
func (g *MultiVoiceGateway) Close() error {
	g.logger.Printf("[MultiVoiceGateway] Closing gateway for session %s", g.sessionID)

	g.closeOnce.Do(func() {
		g.cancel()
		close(g.closeChan)

		// å…³é—­äº‹ä»¶é˜Ÿåˆ—ï¼ˆç­‰å¾…æ‰€æœ‰å¾…å¤„ç†äº‹ä»¶å®Œæˆï¼‰
		if g.eventQueue != nil {
			stats := g.eventQueue.GetStats()
			g.logger.Printf("[MultiVoiceGateway] Event queue stats: %+v", stats)
			if err := g.eventQueue.Close(); err != nil {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸  Error closing event queue: %v", err)
			}
		}

		// æ¸…ç†å…ƒæ•°æ®æ³¨å†Œè¡¨
		if g.metadataRegistry != nil {
			g.metadataRegistry.Clear()
			g.logger.Printf("[MultiVoiceGateway] âœ… Metadata registry cleared")
		}

		// å…³é—­éŸ³è‰²æ± 
		if g.voicePool != nil {
			_ = g.voicePool.Close()
		}

		// å…³é—­å®¢æˆ·ç«¯è¿æ¥
		g.clientConnLock.Lock()
		if g.clientConn != nil {
			_ = g.clientConn.Close()
		}
		g.clientConnLock.Unlock()
	})

	return nil
}

// Done è¿”å›ä¸€ä¸ªåœ¨è¿æ¥å…³é—­æ—¶å…³é—­çš„ channel
func (g *MultiVoiceGateway) Done() <-chan struct{} {
	return g.closeChan
}
