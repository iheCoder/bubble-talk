package gateway

import (
	"context"
	"encoding/base64"
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"sync"
	"time"

	"bubble-talk/server/internal/tool"

	"github.com/gorilla/websocket"
)

// MultiVoiceGateway æ˜¯æ”¯æŒå¤šéŸ³è‰²çš„è¯­éŸ³ç½‘å…³
// æ ¸å¿ƒæ¶æ„ï¼š
//  1. æ¯ä¸ªè§’è‰²ä¸€ä¸ªç‹¬ç«‹çš„ Realtime è¿æ¥ï¼ˆvoice å›ºå®šï¼‰ï¼šè´Ÿè´£è¯¥è§’è‰²çš„è¯­éŸ³åˆæˆï¼ˆTTSï¼‰å’Œå¯¹è¯é€»è¾‘ã€‚
//  2. ä¸€ä¸ª ASR ä¸“ç”¨è¿æ¥ï¼ˆåªåšè¯­éŸ³è¯†åˆ«ï¼‰ï¼šè´Ÿè´£æ¥æ”¶ç”¨æˆ·çš„éŸ³é¢‘æµï¼Œè¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰ã€‚
//     è¿™ä¸ªè¿æ¥é€šå¸¸é…ç½®ä¸ºä¸ç”ŸæˆéŸ³é¢‘ï¼Œæˆ–è€…ç”Ÿæˆçš„éŸ³é¢‘è¢«ä¸¢å¼ƒã€‚
//  3. é€šè¿‡"æ–‡æœ¬é•œåƒ"è®©æ‰€æœ‰è¿æ¥å…±äº«å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
//     - å½“ ASR è¯†åˆ«åˆ°ç”¨æˆ·è¯´è¯æ—¶ï¼Œå°†æ–‡æœ¬ä½œä¸º Text Item æ³¨å…¥åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ã€‚
//     - å½“æŸä¸ªè§’è‰²è¯´è¯æ—¶ï¼Œå°†å…¶å›å¤æ–‡æœ¬ä½œä¸º Assistant Item æ³¨å…¥åˆ°å…¶ä»–è§’è‰²è¿æ¥ã€‚
//     è¿™æ ·æ‰€æœ‰è¿æ¥éƒ½èƒ½ç»´æŠ¤å®Œæ•´çš„å¯¹è¯å†å²ã€‚
type MultiVoiceGateway struct {
	sessionID string

	// å®¢æˆ·ç«¯è¿æ¥ï¼šä¸å‰ç«¯ï¼ˆWeb/Appï¼‰çš„ WebSocket è¿æ¥ï¼Œä¼ è¾“éŸ³é¢‘æµå’Œæ§åˆ¶æŒ‡ä»¤
	clientConn     *websocket.Conn
	clientConnLock sync.Mutex

	// éŸ³è‰²æ± ï¼ˆç®¡ç†å¤šä¸ªè§’è‰²è¿æ¥ï¼‰ï¼šå°è£…äº†ä¸ OpenAI Realtime API çš„å¤šä¸ªè¿æ¥
	voicePool *VoicePool
	// voicePoolReady ç”¨äºåœ¨ Start å®Œæˆ voicePool åˆå§‹åŒ–åå”¤é†’å‘è¨€é˜Ÿåˆ—ã€‚
	// æ³¨æ„ï¼šSendInstructions å¯èƒ½åœ¨ Start ä¹‹å‰è¢«è°ƒç”¨ï¼ˆæ¯”å¦‚å¼€åœºç¼–æ’æ›´æ—©åˆ°è¾¾ï¼‰ã€‚
	voicePoolReady chan struct{}
	voicePoolOnce  sync.Once

	// äº‹ä»¶å¤„ç†å™¨ï¼ˆç”± Orchestrator æ³¨å…¥ï¼‰ï¼šç”¨äºå°†ç½‘å…³æ”¶åˆ°çš„ä¸šåŠ¡äº‹ä»¶ï¼ˆå¦‚ç”¨æˆ·è¯´è¯ã€æ’è¯ã€é€€å‡ºç­‰ï¼‰è½¬å‘ç»™ç¼–æ’å™¨
	eventHandler EventHandler

	// äº‹ä»¶é˜Ÿåˆ—ï¼šä¸²è¡Œå¤„ç†äº‹ä»¶ï¼Œé˜²æ­¢å¹¶å‘ä¿®æ”¹ SessionState
	eventQueue *EventQueue

	// å·¥å…·æ³¨å†Œè¡¨ï¼ˆæ”¯æŒfunction callingï¼‰ï¼šæ‰€æœ‰è§’è‰²å…±äº«çš„å·¥å…·é›†
	toolRegistry *tool.ToolRegistry

	// å“åº”å…ƒæ•°æ®æ³¨å†Œè¡¨ï¼ˆè§£å†³éŸ³é¢‘ä¸å…ƒæ•°æ®å…³è”é—®é¢˜ï¼‰
	metadataRegistry *ResponseMetadataRegistry

	// çŠ¶æ€ç®¡ç†
	ctx       context.Context
	cancel    context.CancelFunc
	closeOnce sync.Once
	closeChan chan struct{}

	// å‘è¨€è°ƒåº¦ï¼šè§£å†³â€œä¸»æŒäºº/ç»æµå­¦å®¶åŒæ—¶è¯´è¯ï¼ˆéŸ³é¢‘äº¤é”™ï¼‰â€çš„é—®é¢˜ã€‚
	// è®¾è®¡åŸåˆ™ï¼š
	// - SendInstructions åªå…¥é˜Ÿï¼Œä¸é˜»å¡ Orchestrator çš„äº‹ä»¶å¤„ç†ï¼ˆé¿å… EventQueue å †ç§¯ï¼‰ã€‚
	// - ä»»æ„æ—¶åˆ»åªå…è®¸ä¸€ä¸ªè§’è‰² CreateResponseï¼›ä¸‹ä¸€ä¸ªè§’è‰²å¿…é¡»ç­‰ä¸Šä¸€ä¸ª response.done/cancelledã€‚
	speechMu       sync.Mutex
	speechCond     *sync.Cond
	speechQueue    []speechRequest
	speechEndedCh  chan speechEnded
	speechLoopOnce sync.Once

	// ASR äº‹ä»¶æºé…ç½®ï¼šè§£å†³"åŒç»ˆæ€äº‹ä»¶æº"é—®é¢˜
	// true: åªä½¿ç”¨ conversation.item.input_audio_transcription.completed
	// false: åªä½¿ç”¨ response.done/response.audio_transcript.done
	useTranscriptionCompleted bool

	// å½“å‰å“åº”çš„å…ƒæ•°æ®ï¼ˆè§’è‰²ã€Beatç­‰ï¼‰ï¼šè®°å½•å½“å‰æ­£åœ¨è¯´è¯çš„è§’è‰²å’Œå¯¹åº”çš„å‰§æƒ…èŠ‚æ‹ä¿¡æ¯
	activeMetadata     map[string]interface{}
	activeMetadataLock sync.RWMutex

	// ASR å»é‡ï¼ˆé¿å… response.done ä¸ response.audio_transcript.done é‡å¤è§¦å‘ï¼‰
	// OpenAI Realtime API å¯èƒ½ä¼šé€šè¿‡å¤šç§äº‹ä»¶è¿”å›è½¬å†™ç»“æœï¼Œæˆ‘ä»¬éœ€è¦å»é‡ä»¥é¿å…é‡å¤å¤„ç†
	asrDedupMu          sync.Mutex
	lastASRResponseID   string
	lastASRTranscript   string
	lastASRTranscriptAt time.Time

	// åºåˆ—å·ç”Ÿæˆå™¨ï¼ˆç”¨äº ServerMessageï¼‰ï¼šä¿è¯å‘é€ç»™å®¢æˆ·ç«¯çš„æ¶ˆæ¯æœ‰åº
	seqCounter int64
	seqLock    sync.Mutex

	// éŸ³é¢‘é—¸é—¨ï¼šç”¨äºå®ç°â€œç«‹åˆ»æ‰“æ–­â€çš„ä½“éªŒä¿éšœã€‚
	// èƒŒæ™¯ï¼šå³ä¾¿æˆ‘ä»¬å‘é€äº† response.cancelï¼ŒRealtime å¯èƒ½ä»ä¼šæœ‰å°‘é‡ in-flight çš„ audio.deltaï¼›
	// è‹¥ç»§ç»­è½¬å‘ç»™å‰ç«¯ï¼Œç”¨æˆ·ä¼šæ„ŸçŸ¥ä¸ºâ€œæ‰“æ–­ä¸ç”Ÿæ•ˆâ€ã€‚å› æ­¤åœ¨æ£€æµ‹åˆ°ç”¨æˆ·å¼€å£/æ’è¯æ—¶ï¼Œ
	// ç›´æ¥åœ¨ç½‘å…³ä¾§åœæ­¢è½¬å‘å½“å‰ speaker çš„éŸ³é¢‘ï¼Œç›´åˆ°è¯¥ response ç»“æŸã€‚
	audioGateMu sync.Mutex
	mutedRole   string
	mutedAt     time.Time
	mutedReason string

	// é…ç½®
	config GatewayConfig

	// æ—¥å¿—
	logger *log.Logger
}

type speechRequest struct {
	role         string
	instructions string
	metadata     map[string]interface{}
	enqueuedAt   time.Time
}

type speechEnded struct {
	role       string
	responseID string
	cancelled  bool
	endedAt    time.Time
}

// NewMultiVoiceGateway åˆ›å»ºä¸€ä¸ªæ”¯æŒå¤šéŸ³è‰²çš„ç½‘å…³
func NewMultiVoiceGateway(sessionID string, clientConn *websocket.Conn, config GatewayConfig) *MultiVoiceGateway {
	ctx, cancel := context.WithCancel(context.Background())

	logger := log.Default()
	g := &MultiVoiceGateway{
		sessionID:  sessionID,
		clientConn: clientConn,
		ctx:        ctx,
		cancel:     cancel,
		closeChan:  make(chan struct{}),
		config:     config,
		logger:     logger,
		// é»˜è®¤ä½¿ç”¨ transcription.completed ä½œä¸ºå”¯ä¸€ ASR äº‹ä»¶æº
		useTranscriptionCompleted: true,
		// åˆå§‹åŒ–å…ƒæ•°æ®æ³¨å†Œè¡¨
		metadataRegistry: NewResponseMetadataRegistry(logger),
		voicePoolReady:   make(chan struct{}),
		speechQueue:      make([]speechRequest, 0, 8),
		speechEndedCh:    make(chan speechEnded, 32),
	}
	g.speechCond = sync.NewCond(&g.speechMu)

	return g
}

// SetEventHandler è®¾ç½®äº‹ä»¶å¤„ç†å™¨ï¼ˆOrchestrator æ³¨å…¥ï¼‰
func (g *MultiVoiceGateway) SetEventHandler(handler EventHandler) {
	g.eventHandler = handler
	// åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—ï¼Œç¡®ä¿äº‹ä»¶ä¸²è¡Œå¤„ç†
	if g.eventQueue == nil {
		g.eventQueue = NewEventQueue(g.sessionID, handler, g.logger)
		g.logger.Printf("[MultiVoiceGateway] Event queue created for session %s", g.sessionID)
	}
}

// SetToolRegistry è®¾ç½®å·¥å…·æ³¨å†Œè¡¨
func (g *MultiVoiceGateway) SetToolRegistry(registry *tool.ToolRegistry) {
	g.toolRegistry = registry
	// å¦‚æœéŸ³è‰²æ± å·²ç»åˆå§‹åŒ–ï¼Œä¼ é€’ç»™æ‰€æœ‰è§’è‰²è¿æ¥
	if g.voicePool != nil {
		g.voicePool.SetToolRegistry(registry)
	}
}

// Start å¯åŠ¨ç½‘å…³
func (g *MultiVoiceGateway) Start(ctx context.Context) error {
	g.logger.Printf("[MultiVoiceGateway] Starting gateway for session %s", g.sessionID)

	if g.clientConn == nil {
		return fmt.Errorf("clientConn is nil")
	}

	// 1. åˆ›å»ºéŸ³è‰²æ± 
	g.logger.Printf("[MultiVoiceGateway] Creating voice pool...")
	roleVoices := make(map[string]string)
	for role, profile := range g.config.RoleProfiles {
		roleVoices[role] = profile.Voice
		g.logger.Printf("[MultiVoiceGateway] Role %s -> Voice %s", role, profile.Voice)
	}

	poolConfig := VoicePoolConfig{
		OpenAIAPIKey:                 g.config.OpenAIAPIKey,
		Model:                        g.config.Model,
		DefaultInstructions:          g.config.DefaultInstructions,
		InputAudioFormat:             g.config.InputAudioFormat,
		OutputAudioFormat:            g.config.OutputAudioFormat,
		InputAudioTranscriptionModel: g.config.InputAudioTranscriptionModel,
		RoleVoices:                   roleVoices,
	}

	g.voicePool = NewVoicePool(g.sessionID, poolConfig)

	// ä¼ é€’å·¥å…·æ³¨å†Œè¡¨åˆ°éŸ³è‰²æ± ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
	if g.toolRegistry != nil {
		g.voicePool.SetToolRegistry(g.toolRegistry)
		g.logger.Printf("[MultiVoiceGateway] Tool registry passed to voice pool")
	}

	// 2. åˆå§‹åŒ–éŸ³è‰²æ± ï¼ˆåˆ›å»ºæ‰€æœ‰ RoleConn å’Œ ASRConnï¼‰
	g.logger.Printf("[MultiVoiceGateway] Initializing voice pool...")
	if err := g.voicePool.Initialize(ctx); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to initialize voice pool: %v", err)
		return fmt.Errorf("initialize voice pool: %w", err)
	}
	g.logger.Printf("[MultiVoiceGateway] âœ… Voice pool initialized")
	g.voicePoolOnce.Do(func() { close(g.voicePoolReady) })

	// 3. å¯åŠ¨äº‹ä»¶å¾ªç¯
	g.logger.Printf("[MultiVoiceGateway] Starting event loops...")
	go g.clientReadLoop()
	go g.asrReadLoop()
	go g.roleConnsReadLoop()
	g.speechLoopOnce.Do(func() { go g.speechLoop() })

	g.logger.Printf("[MultiVoiceGateway] âœ… Gateway fully started for session %s", g.sessionID)
	return nil
}

// clientReadLoop ä»å®¢æˆ·ç«¯è¯»å–æ¶ˆæ¯ï¼ˆäº‹ä»¶+éŸ³é¢‘ï¼‰
func (g *MultiVoiceGateway) clientReadLoop() {
	defer g.Close()

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := g.clientConn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] client read error: %v", err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			// JSON äº‹ä»¶
			if err := g.handleClientEvent(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle client event error: %v", err)
				g.sendErrorToClient(err.Error())
			}
		} else if messageType == websocket.BinaryMessage {
			// éŸ³é¢‘æ•°æ®ï¼ˆå‘é€åˆ° ASR è¿æ¥ï¼‰
			if err := g.handleClientAudio(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle client audio error: %v", err)
			}
		}
	}
}

// handleClientEvent å¤„ç†å®¢æˆ·ç«¯ JSON äº‹ä»¶
func (g *MultiVoiceGateway) handleClientEvent(data []byte) error {
	var msg ClientMessage
	if err := json.Unmarshal(data, &msg); err != nil {
		return fmt.Errorf("unmarshal client message: %w", err)
	}

	if msg.ClientTS.IsZero() {
		msg.ClientTS = time.Now()
	}

	g.logger.Printf("[MultiVoiceGateway] client event: type=%s event_id=%s", msg.Type, msg.EventID)

	switch msg.Type {
	case EventTypeBargeIn:
		return g.handleBargeIn(&msg)
	case EventTypeExitRequested, EventTypeQuizAnswer:
		return g.forwardToOrchestrator(&msg)
	default:
		return g.forwardToOrchestrator(&msg)
	}
}

// handleClientAudio å¤„ç†å®¢æˆ·ç«¯éŸ³é¢‘æ•°æ®ï¼ˆå‘é€åˆ° ASR è¿æ¥ï¼‰
func (g *MultiVoiceGateway) handleClientAudio(audioData []byte) error {
	// å°†éŸ³é¢‘æ•°æ®è½¬å‘åˆ° ASR è¿æ¥
	asrConn, err := g.voicePool.GetASRConn()
	if err != nil {
		return fmt.Errorf("get ASR conn: %w", err)
	}

	encoded := base64.StdEncoding.EncodeToString(audioData)
	append := RealtimeInputAudioBufferAppend{
		Type:  "input_audio_buffer.append",
		Audio: encoded,
	}

	return asrConn.SendMessage(append)
}

// handleBargeIn å¤„ç†æ’è¯ä¸­æ–­
func (g *MultiVoiceGateway) handleBargeIn(msg *ClientMessage) error {
	g.logger.Printf("[MultiVoiceGateway] barge-in detected, canceling active response")

	// æ’è¯æ„å‘³ç€ç”¨æˆ·è¦æ¥ç®¡è¯ç­’ï¼šæŠŠæ‰€æœ‰â€œå¾…æ’­æŠ¥â€çš„æ—§æŒ‡ä»¤éƒ½ä¸¢æ‰ï¼Œé¿å…è¿‡æœŸå†…å®¹æ’æ’­ã€‚
	g.dropPendingSpeech("client_barge_in")

	// å–æ¶ˆå½“å‰æ­£åœ¨è¯´è¯çš„è§’è‰²çš„å“åº”
	g.muteActiveSpeakerAudio("client_barge_in")
	if err := g.voicePool.CancelCurrentResponse(); err != nil {
		g.logger.Printf("[MultiVoiceGateway] failed to cancel response: %v", err)
	}

	// é€šçŸ¥å®¢æˆ·ç«¯æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
	g.sendTTSInterruptedToClient("client_barge_in")

	// è½¬å‘ç»™ Orchestrator
	return g.forwardToOrchestrator(msg)
}

// forwardToOrchestrator è½¬å‘äº‹ä»¶ç»™ Orchestrator
// ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨äº‹ä»¶é˜Ÿåˆ—ä¸²è¡Œå¤„ç†ï¼Œé˜²æ­¢ SessionState å¹¶å‘ä¿®æ”¹
func (g *MultiVoiceGateway) forwardToOrchestrator(msg *ClientMessage) error {
	if g.eventHandler == nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  no event handler set, dropping event: %s", msg.Type)
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] Forwarding event to Orchestrator: type=%s text=%s", msg.Type, msg.Text)

	// ä½¿ç”¨äº‹ä»¶é˜Ÿåˆ—ä»£æ›¿ç›´æ¥çš„ goroutineï¼Œä¿è¯ï¼š
	// 1. åŒä¸€ session çš„æ‰€æœ‰äº‹ä»¶ä¸²è¡Œå¤„ç†ï¼ˆé˜²æ­¢å¹¶å‘å†™ SessionStateï¼‰
	// 2. äº‹ä»¶æŒ‰æ¥æ”¶é¡ºåºå¤„ç†ï¼ˆé˜²æ­¢ asr_final å’Œ assistant_text ä¹±åºï¼‰
	if g.eventQueue != nil {
		if err := g.eventQueue.Enqueue(msg); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âŒ Failed to enqueue event: %v", err)
			g.sendErrorToClient(fmt.Sprintf("Event queue error: %v", err))
			return err
		}
		return nil
	}

	// é™çº§æ–¹æ¡ˆï¼šå¦‚æœäº‹ä»¶é˜Ÿåˆ—æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŒæ­¥å¤„ç†ï¼ˆä¸å†ä½¿ç”¨ goroutineï¼‰
	// è¿™æ ·è™½ç„¶å¯èƒ½é˜»å¡ï¼Œä½†è‡³å°‘ä¸ä¼šå‡ºç°å¹¶å‘é—®é¢˜
	g.logger.Printf("[MultiVoiceGateway] âš ï¸  Event queue not initialized, using synchronous processing")
	ctx, cancel := context.WithTimeout(g.ctx, 10*time.Second)
	defer cancel()

	if err := g.eventHandler(ctx, msg); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Orchestrator handler error: %v", err)
		g.sendErrorToClient(fmt.Sprintf("Orchestrator error: %v", err))
		return err
	}

	g.logger.Printf("[MultiVoiceGateway] âœ… Orchestrator handled event successfully")
	return nil
}

// asrReadLoop ä» ASR è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) asrReadLoop() {
	asrConn, err := g.voicePool.GetASRConn()
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to get ASR conn: %v", err)
		return
	}

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := asrConn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] ASR read error: %v", err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			if err := g.handleASREvent(data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle ASR event error: %v", err)
			}
		}
	}
}

// handleASREvent å¤„ç† ASR è¿æ¥çš„äº‹ä»¶
// ASR è¿æ¥çš„ä¸»è¦èŒè´£æ˜¯æ¥æ”¶ç”¨æˆ·éŸ³é¢‘å¹¶è½¬å†™ä¸ºæ–‡æœ¬ï¼Œå®ƒä¸åº”è¯¥ç”ŸæˆéŸ³é¢‘å“åº”ã€‚
// ä½†ç”±äº OpenAI Realtime API çš„æœºåˆ¶ï¼ŒVAD è§¦å‘æ—¶å¯èƒ½ä¼šè‡ªåŠ¨åˆ›å»º responseã€‚
// æˆ‘ä»¬éœ€è¦å¤„ç†è¿™äº›äº‹ä»¶ï¼Œæå–è½¬å†™æ–‡æœ¬ï¼Œå¹¶ç¡®ä¿ä¸ä¼šäº§ç”Ÿä¸éœ€è¦çš„éŸ³é¢‘è¾“å‡ºã€‚
func (g *MultiVoiceGateway) handleASREvent(data []byte) error {
	var event map[string]interface{}
	if err := json.Unmarshal(data, &event); err != nil {
		return fmt.Errorf("unmarshal ASR event: %w", err)
	}

	eventType, _ := event["type"].(string)
	g.logger.Printf("[MultiVoiceGateway] ASR event: %s", eventType)

	switch eventType {
	case "error":
		// è®°å½• API é”™è¯¯
		g.logRealtimeError("ASR", event)
		return nil

	// ASR ç›¸å…³äº‹ä»¶
	case "input_audio_buffer.speech_started":
		// VAD æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯
		// ä¿®å¤æ–¹æ¡ˆï¼šæœåŠ¡ç«¯å…œåº•çš„æ’è¯æ£€æµ‹
		g.logger.Printf("[MultiVoiceGateway] ğŸ¤ User started speaking (server-side VAD)")

		activeSpeaker := ""
		if g.voicePool != nil {
			activeSpeaker = g.voicePool.GetSpeakingRole()
		}

		// ç»™å‰ç«¯ä¸€ä¸ªâ€œæˆ‘å¬åˆ°äº†â€çš„å¼ºä¿¡å·ï¼Œä¾¿äº UI åšå½•éŸ³æ€/æ‰“æ–­æ€è”åŠ¨ã€‚
		g.sendToClient(&ServerMessage{
			Type:     EventTypeSpeechStarted,
			ServerTS: time.Now(),
		})

		// ç”¨æˆ·å¼€å£æ—¶ï¼šä¸¢å¼ƒå°šæœªæ’­æ”¾çš„æ—§æŒ‡ä»¤ï¼Œé¿å…â€œè¿˜æ²¡è¯´å®Œå°±åˆå‘ç°è¦è¯´å¦ä¸€æ®µâ€çš„ç²¾ç¥åˆ†è£‚æ„Ÿã€‚
		g.dropPendingSpeech("server_vad_speech_started")

		// æœåŠ¡ç«¯å…œåº•ï¼šå¦‚æœæœ‰è§’è‰²æ­£åœ¨è¯´è¯ï¼Œç«‹å³å–æ¶ˆ
		// è¿™æ˜¯å¯¹å®¢æˆ·ç«¯ barge_in çš„è¡¥å……ï¼Œé˜²æ­¢å®¢æˆ·ç«¯å»¶è¿Ÿæˆ–æœªå‘é€ barge_in
		if activeSpeaker != "" {
			g.muteRoleAudio(activeSpeaker, "server_vad_speech_started")
		}
		if err := g.voicePool.CancelCurrentResponse(); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸  Server-side barge-in cancel failed: %v", err)
		} else {
			if activeSpeaker != "" {
				g.logger.Printf("[MultiVoiceGateway] âœ… Server-side barge-in: cancelled current response (role=%s)", activeSpeaker)
			} else {
				g.logger.Printf("[MultiVoiceGateway] âœ… Server-side barge-in: no active speaker")
			}
		}

		// ä»…åœ¨ç¡®å®æœ‰ AI åœ¨æ’­æ—¶æ‰æ¸…ç©ºç¼“å†²ï¼Œé¿å…å‰ç«¯æ”¶åˆ°å™ªéŸ³äº‹ä»¶ã€‚
		if activeSpeaker != "" {
			g.sendTTSInterruptedToClient("server_vad_speech_started")
		}

		return nil

	case "input_audio_buffer.speech_stopped":
		// VAD æ£€æµ‹åˆ°ç”¨æˆ·åœæ­¢è¯´è¯
		// æ³¨æ„ä¸ç­‰åŒäºç”¨æˆ·çœŸçš„è¯´å®Œäº†ï¼Œå¯èƒ½åªæ˜¯çŸ­æš‚åœé¡¿ã€VAD é™éŸ³é˜ˆå€¼è§¦å‘
		g.logger.Printf("[MultiVoiceGateway] User stopped speaking")
		g.sendToClient(&ServerMessage{
			Type:     EventTypeSpeechStopped,
			ServerTS: time.Now(),
		})
		return nil

	case "conversation.item.input_audio_transcription.completed":
		// ASR å·²å®Œæˆï¼ŒæœåŠ¡å™¨ç”Ÿæˆäº†"æœ€ç»ˆå¯ç”¨çš„ç”¨æˆ·è¯­éŸ³æ–‡æœ¬"ï¼Œç”¨æˆ·"è¯´äº†ä»€ä¹ˆ"åœ¨è¿™ä¸€åˆ»æ‰ç¡®å®š
		// å½“ session é…ç½®äº† input_audio_transcription æ—¶è§¦å‘
		// ä¿®å¤æ–¹æ¡ˆï¼šè¿™æ˜¯ ASR çš„å”¯ä¸€çœŸç›¸æ¥æºï¼ˆå¦‚æœ useTranscriptionCompleted=trueï¼‰
		if g.useTranscriptionCompleted {
			return g.handleASRTranscriptionCompleted(event)
		}
		g.logger.Printf("[MultiVoiceGateway] Ignoring transcription.completed (using response.done as ASR source)")
		return nil

	// response ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
	case "response.created":
		// ä¸€ä¸ªæ–°çš„ response ç”Ÿå‘½å‘¨æœŸè¢«åˆ›å»ºäº†
		// ASR è¿æ¥ä¸åº”è¯¥åˆ›å»º responseï¼Œä½†ç”±äº API é»˜è®¤è¡Œä¸ºï¼ˆVAD è§¦å‘ responseï¼‰ï¼Œå®ƒå¯èƒ½ä¼šåˆ›å»ºã€‚
		// æˆ‘ä»¬éœ€è¦è®°å½•è¿™ä¸ª response IDï¼Œä»¥ä¾¿åç»­æå–è½¬å†™æˆ–å–æ¶ˆå®ƒã€‚
		// å…³é”®ç‚¹ï¼šASR è¿æ¥çš„ instructions é€šå¸¸è®¾ç½®ä¸ºç©ºæˆ–"åªåšè½¬å†™"ï¼Œä»¥å‡å°‘æ¨¡å‹ç”Ÿæˆå†…å®¹çš„æ¶ˆè€—ã€‚
		responseID, _ := event["response"].(map[string]interface{})["id"].(string)
		if responseID != "" {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸ ASR created response %s (will extract transcription and cancel)", responseID)
			asrConn, _ := g.voicePool.GetASRConn()
			if asrConn != nil {
				asrConn.SetActiveResponse(responseID)
				// ASR è¿æ¥ä¸åº”äº§ç”Ÿä»»ä½•å¯å¬è¾“å‡ºã€‚è‹¥æœåŠ¡ç«¯æ„å¤–åˆ›å»ºäº† responseï¼Œä¼˜å…ˆå–æ¶ˆï¼Œé¿å…æ— æ„ä¹‰çš„éŸ³é¢‘ç”Ÿæˆ/å¸¦å®½æ¶ˆè€—ã€‚
				// å½“ useTranscriptionCompleted=true æ—¶ï¼Œç”¨æˆ·æ–‡æœ¬ä»¥ transcription.completed ä¸ºå‡†ï¼Œä¸ä¾èµ–è¿™ä¸ª responseã€‚
				if g.useTranscriptionCompleted {
					if err := asrConn.CancelResponse(); err != nil {
						g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel unexpected ASR response (response_id=%s): %v", responseID, err)
					} else {
						g.logger.Printf("[MultiVoiceGateway] âœ… Cancelled unexpected ASR response early (response_id=%s)", responseID)
					}
				}
			}
		}

	case "response.audio.delta":
		// ASR è¿æ¥ä¸åº”è¯¥è¾“å‡ºéŸ³é¢‘ï¼›ä¸€æ—¦å‡ºç°ï¼Œç«‹åˆ»å–æ¶ˆï¼Œé¿å…æŒç»­ç”Ÿæˆæ— ç”¨éŸ³é¢‘ã€‚
		asrConn, _ := g.voicePool.GetASRConn()
		if asrConn != nil {
			if err := asrConn.CancelResponse(); err != nil {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel ASR audio output: %v", err)
			}
		}
		return nil

	case "response.audio_transcript.delta":
		// assistant è¯­éŸ³è¾“å‡ºå¯¹åº”çš„â€œè½¬å†™æ–‡æœ¬ï¼ˆå®æ—¶ï¼‰â€çš„å¢é‡
		// å¿½ç•¥ ASR çš„éŸ³é¢‘è½¬å†™å¢é‡ï¼ˆæˆ‘ä»¬åªå…³å¿ƒæœ€ç»ˆæ–‡æœ¬ï¼Œé¿å…é¢‘ç¹åˆ·æ–° UI æˆ–é€»è¾‘ï¼‰
		return nil

	case "response.audio_transcript.done", "response.done":
		// assistant è¯­éŸ³è½¬å†™æ–‡æœ¬å·²å®Œæˆï¼Œresponse ç”Ÿå‘½å‘¨æœŸå½»åº•ç»“æŸ
		// ä¿®å¤æ–¹æ¡ˆï¼šåªåœ¨ useTranscriptionCompleted=false æ—¶ä½¿ç”¨è¿™ä¸ªä½œä¸º ASR æº
		if !g.useTranscriptionCompleted {
			return g.handleASRResponseDone(event)
		}

		// å¦‚æœä½¿ç”¨ transcription.completedï¼Œè¿™é‡Œä»ç„¶è¦å–æ¶ˆ ASR responseï¼Œä½†ä¸ä¸ŠæŠ¥æ–‡æœ¬
		g.logger.Printf("[MultiVoiceGateway] ASR response done (will cancel but not report, using transcription.completed as source)")
		asrConn, _ := g.voicePool.GetASRConn()
		if asrConn != nil {
			if err := asrConn.CancelResponse(); err != nil {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel ASR response: %v", err)
			}
		}
		return nil

	}

	return nil
}

// handleASRResponseDone ä» ASR response ä¸­æå–è½¬å†™å¹¶å–æ¶ˆ response
// ç›®çš„ï¼šè·å–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å†…å®¹ï¼ŒåŒæ—¶ç¡®ä¿ ASR è¿æ¥ä¸æ’­æ”¾éŸ³é¢‘ã€‚
func (g *MultiVoiceGateway) handleASRResponseDone(event map[string]interface{}) error {
	// ä» response ä¸­æå–è½¬å†™
	// ç»“æ„å¯èƒ½æ˜¯ response.output[].content[].transcript (response.done)
	// æˆ–è€…æ˜¯ç›´æ¥çš„ transcript å­—æ®µ (response.audio_transcript.done)
	var transcript string
	responseID := ""

	if event["type"] == "response.done" {
		response, _ := event["response"].(map[string]interface{})
		if response != nil {
			responseID, _ = response["id"].(string)
		}
		output, _ := response["output"].([]interface{})

		for _, item := range output {
			itemMap, _ := item.(map[string]interface{})
			itemType, _ := itemMap["type"].(string)
			if itemType == "message" {
				content, _ := itemMap["content"].([]interface{})
				for _, c := range content {
					cMap, _ := c.(map[string]interface{})
					if cMap["type"] == "audio" {
						text, _ := cMap["transcript"].(string)
						transcript += text
					}
				}
			}
		}
	} else {
		// response.audio_transcript.done
		if v, ok := event["response_id"].(string); ok {
			responseID = v
		}
		transcript, _ = event["transcript"].(string)
	}

	if transcript == "" {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸ Empty ASR transcript")
		return nil
	}

	// ASR å»é‡ï¼šé¿å…åŒä¸€ä¸ª response çš„å¤šæ¬¡äº‹ä»¶å¯¼è‡´é‡å¤å¤„ç†
	if g.shouldDropASRResult(responseID, transcript) {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸ Duplicate ASR transcript dropped (response_id=%s)", responseID)
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] ğŸ“ ASR transcription: %s", transcript)

	// å–æ¶ˆ ASR responseï¼ˆæˆ‘ä»¬ä¸éœ€è¦å®ƒçš„éŸ³é¢‘è¾“å‡ºï¼Œé˜²æ­¢å®ƒ"è¯´è¯"ï¼‰
	// è™½ç„¶ response å·²ç» doneï¼Œä½†å–æ¶ˆæ“ä½œå¯ä»¥ç¡®ä¿æ¸…ç†ç›¸å…³çŠ¶æ€
	asrConn, _ := g.voicePool.GetASRConn()
	if asrConn != nil {
		if err := asrConn.CancelResponse(); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸ Failed to cancel ASR response: %v", err)
		}
	}

	// 1. åŒæ­¥ç”¨æˆ·æ–‡æœ¬åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
	// è¿™æ˜¯å¤šéŸ³è‰²æ¶æ„çš„å…³é”®ï¼šè®©æ‰€æœ‰è§’è‰²éƒ½çŸ¥é“ç”¨æˆ·è¯´äº†ä»€ä¹ˆï¼Œ
	// å³ä½¿å®ƒä»¬ä¸æ˜¯æ¥æ”¶éŸ³é¢‘çš„é‚£ä¸ªè¿æ¥ã€‚
	if err := g.voicePool.SyncUserText(transcript); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync user text: %v", err)
	}

	// 2. è½¬å‘ç»™ Orchestrator å¤„ç†
	// Orchestrator ä¼šæ ¹æ®è¿™ä¸ªæ–‡æœ¬å†³å®šä¸‹ä¸€æ­¥çš„å‰§æƒ…ï¼ˆBeatï¼‰æˆ–è®©å“ªä¸ªè§’è‰²å›ç­”ã€‚
	msg := &ClientMessage{
		Type:     EventTypeASRFinal,
		EventID:  fmt.Sprintf("asr_%d", time.Now().UnixNano()),
		Text:     transcript,
		ClientTS: time.Now(),
	}

	return g.forwardToOrchestrator(msg)
}

// handleASRTranscriptionCompleted å¤„ç†è½¬å†™å®Œæˆäº‹ä»¶
// ä¿®å¤æ–¹æ¡ˆï¼šè¿™æ˜¯ ASR çš„å”¯ä¸€çœŸç›¸æ¥æºï¼ˆå½“ useTranscriptionCompleted=trueï¼‰
// é¿å…ä¸ handleASRResponseDone é‡å¤ä¸ŠæŠ¥åŒä¸€å¥è¯
func (g *MultiVoiceGateway) handleASRTranscriptionCompleted(event map[string]interface{}) error {
	transcript, _ := event["transcript"].(string)
	if transcript == "" {
		g.logger.Printf("[MultiVoiceGateway] Empty transcript, ignoring")
		return nil
	}

	g.logger.Printf("[MultiVoiceGateway] âœ… [PRIMARY ASR SOURCE] User transcript: %s", transcript)

	// ç»™å‰ç«¯ä¸€ä¸ªæ˜ç¡®çš„â€œæœ€ç»ˆè½¬å†™â€ä¿¡å·ï¼Œå¦åˆ™ç”¨æˆ·ä¼šè§‰å¾—â€œç³»ç»Ÿæ²¡å¬åˆ°â€ã€‚
	_ = g.sendToClient(&ServerMessage{
		Type:     EventTypeASRFinal,
		Text:     transcript,
		ServerTS: time.Now(),
	})

	// 1. åŒæ­¥ç”¨æˆ·æ–‡æœ¬åˆ°æ‰€æœ‰è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
	if err := g.voicePool.SyncUserText(transcript); err != nil {
		g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync user text: %v", err)
	}

	// 2. è½¬å‘ç»™ Orchestrator å¤„ç†
	msg := &ClientMessage{
		Type:     EventTypeASRFinal,
		EventID:  fmt.Sprintf("asr_%d", time.Now().UnixNano()),
		Text:     transcript,
		ClientTS: time.Now(),
	}

	return g.forwardToOrchestrator(msg)
}

// roleConnsReadLoop ä»æ‰€æœ‰è§’è‰²è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) roleConnsReadLoop() {
	// ä¸ºæ¯ä¸ªè§’è‰²è¿æ¥å¯åŠ¨ä¸€ä¸ªè¯»å–åç¨‹
	for role := range g.config.RoleProfiles {
		role := role // æ•è·å¾ªç¯å˜é‡
		go g.roleConnReadLoop(role)
	}
}

// roleConnReadLoop ä»æŒ‡å®šè§’è‰²è¿æ¥è¯»å–æ¶ˆæ¯
func (g *MultiVoiceGateway) roleConnReadLoop(role string) {
	conn, err := g.voicePool.GetRoleConn(g.ctx, role)
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] âŒ Failed to get role conn for %s: %v", role, err)
		return
	}

	for {
		select {
		case <-g.closeChan:
			return
		default:
		}

		messageType, data, err := conn.ReadMessage()
		if err != nil {
			if !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) {
				g.logger.Printf("[MultiVoiceGateway] Role %s read error: %v", role, err)
			}
			return
		}

		if messageType == websocket.TextMessage {
			if err := g.handleRoleConnEvent(role, data); err != nil {
				g.logger.Printf("[MultiVoiceGateway] handle role conn event error: %v", err)
			}
		}
	}
}

// handleRoleConnEvent å¤„ç†è§’è‰²è¿æ¥çš„äº‹ä»¶
// è§’è‰²è¿æ¥ä¸»è¦è´Ÿè´£ TTSï¼ˆè¯­éŸ³åˆæˆï¼‰å’Œå¯¹è¯é€»è¾‘ã€‚
// æˆ‘ä»¬éœ€è¦ç›‘å¬è¿™äº›äº‹ä»¶æ¥åŒæ­¥çŠ¶æ€ã€è½¬å‘éŸ³é¢‘ç»™å®¢æˆ·ç«¯ï¼Œä»¥åŠè¿›è¡Œæ–‡æœ¬é•œåƒã€‚
func (g *MultiVoiceGateway) handleRoleConnEvent(role string, data []byte) error {
	var event map[string]interface{}
	if err := json.Unmarshal(data, &event); err != nil {
		return fmt.Errorf("unmarshal role conn event: %w", err)
	}

	eventType, _ := event["type"].(string)
	g.logger.Printf("[MultiVoiceGateway] Role %s event: %s", role, eventType)

	switch eventType {
	case "error":
		g.logRealtimeError("Role "+role, event)
		return nil

	case "response.created":
		// å“åº”åˆ›å»º - æ„å‘³ç€è§’è‰²å‡†å¤‡å¼€å§‹è¯´è¯
		// 1. è®°å½• active response IDï¼Œä»¥ä¾¿åœ¨æ’è¯æ—¶èƒ½å–æ¶ˆå®ƒ
		responseID, _ := event["response"].(map[string]interface{})["id"].(string)
		conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
		if conn != nil {
			conn.SetActiveResponse(responseID)

			// 2. æ³¨å†Œå…ƒæ•°æ®ï¼šå°† responseID ä¸ roleã€metadata å…³è”
			if metadata := conn.GetPendingMetadata(); metadata != nil {
				g.metadataRegistry.Register(responseID, role, metadata)
				g.logger.Printf("[MultiVoiceGateway] âœ… Registered metadata for responseID=%s role=%s",
					responseID, role)
			} else {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸  No pending metadata for responseID=%s role=%s",
					responseID, role)
			}
		}

		// å¦‚æœè¯¥è§’è‰²æ­¤å‰è¢«â€œé—¸é—¨é™éŸ³â€ï¼Œè¯´æ˜ä¸Šä¸€æ¬¡å‘è¨€å·²è¢«ç”¨æˆ·æ‰“æ–­ï¼›æ–°çš„ response.created åˆ°æ¥æ—¶æ¢å¤éŸ³é¢‘è½¬å‘ã€‚
		g.unmuteRoleAudio(role)

		// 3. å‘é€ tts_started ç»™å‰ç«¯ï¼ŒåŒ…å«è§’è‰²ä¿¡æ¯ï¼Œè®©å‰ç«¯æ˜¾ç¤º"æ­£åœ¨è¯´è¯"çš„åŠ¨ç”»
		g.sendTTSStartedToClient(role)

	case "response.audio.delta":
		// éŸ³é¢‘å¢é‡ - è¿™æ˜¯å®æ—¶çš„è¯­éŸ³æ•°æ®
		// æˆ‘ä»¬ç›´æ¥è½¬å‘ç»™å®¢æˆ·ç«¯æ’­æ”¾
		return g.handleAudioDelta(role, event)

	case "response.audio_transcript.delta":
		// æ–‡æœ¬å¢é‡ - å®æ—¶å­—å¹•
		// ç›®å‰åªæ‰“å°æ—¥å¿—ï¼Œå¦‚æœå‰ç«¯éœ€è¦å®æ—¶é€å­—æ˜¾ç¤ºï¼Œå¯ä»¥è½¬å‘è¿™ä¸ªäº‹ä»¶
		delta, _ := event["delta"].(string)
		g.logger.Printf("[MultiVoiceGateway] Role %s transcript delta: %s", role, delta)

	case "response.done":
		// å“åº”å®Œæˆ - è§’è‰²è¯´å®Œäº†ä¸€å¥è¯
		// 1. é€šçŸ¥å‰ç«¯ TTS ç»“æŸ
		g.sendTTSCompletedToClient(role)
		// 2. æå–å®Œæ•´æ–‡æœ¬ï¼Œè¿›è¡Œæ–‡æœ¬é•œåƒï¼ˆåŒæ­¥ç»™å…¶ä»–è§’è‰²ï¼‰å’Œä¸šåŠ¡å¤„ç†
		return g.handleResponseDone(role, event)

	case "response.cancelled":
		// å“åº”è¢«å–æ¶ˆ - æ’è¯ä¸­æ–­æˆåŠŸ
		// ä¿®å¤æ–¹æ¡ˆï¼šå¤„ç†å–æ¶ˆåçš„çŠ¶æ€æ”¶æ•›
		g.logger.Printf("[MultiVoiceGateway] âœ… Role %s response cancelled (barge-in successful)", role)

		// æå– responseID
		response, _ := event["response"].(map[string]interface{})
		responseID, _ := response["id"].(string)

		// 1. æ¸…é™¤æ´»è·ƒå“åº”
		conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
		if conn != nil {
			conn.ClearActiveResponse()
		}

		// 2. æ¸…é™¤æ­£åœ¨è¯´è¯çš„è§’è‰²
		g.voicePool.ClearSpeakingRole()

		// 2.1 æ¢å¤éŸ³é¢‘è½¬å‘ï¼ˆé¿å…åç»­åŒè§’è‰²æ–° response è¢«è¯¯ä¼¤ï¼‰
		g.unmuteRoleAudio(role)

		// 3. æ³¨é”€å…ƒæ•°æ®
		if responseID != "" {
			g.metadataRegistry.Unregister(responseID)
			g.logger.Printf("[MultiVoiceGateway] âœ… Unregistered metadata for cancelled responseID=%s", responseID)
		}

		// 4. é€šçŸ¥å‰ç«¯ TTS å·²ä¸­æ–­
		g.sendTTSCompletedToClient(role)

		g.notifySpeechEnded(speechEnded{
			role:       role,
			responseID: responseID,
			cancelled:  true,
			endedAt:    time.Now(),
		})

		return nil
	}

	return nil
}

const asrDuplicateWindow = 2 * time.Second

// shouldDropASRResult ç”¨äºå»é‡ ASR çš„é‡å¤å®Œæˆäº‹ä»¶ã€‚
//
// è¯´æ˜ï¼ˆä¸­æ–‡ï¼‰ï¼š
// è¿™ä¸ªå‡½æ•°ç”¨äºé¿å… ASR è¿æ¥é‡å¤è§¦å‘åŒä¸€æ¡æœ€ç»ˆè½¬å†™ï¼ˆcompletionï¼‰å¯¼è‡´çš„é‡å¤ä¸ŠæŠ¥ã€‚
// ASR åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¹åŒä¸€æ®µè¯­éŸ³æ—¢äº§ç”Ÿ response.doneï¼ˆå®Œæ•´ response åŒ…å« outputï¼‰
// åˆäº§ç”Ÿ response.audio_transcript.doneï¼ˆå•ç‹¬çš„è½¬å†™å®Œæˆäº‹ä»¶ï¼‰ï¼Œæˆ–è€…å®¢æˆ·ç«¯/æœåŠ¡ç«¯åœ¨çŸ­æ—¶é—´å†…
// æ”¶åˆ°åŒæ ·çš„è½¬å†™ä¸¤æ¬¡ã€‚å› æ­¤éœ€è¦ç®€å•çš„å»é‡ç­–ç•¥æ¥é¿å…ä¸Šå±‚ï¼ˆæ¯”å¦‚ Orchestratorï¼‰é‡å¤å¤„ç†ç›¸åŒçš„æ–‡æœ¬ã€‚
//
// å»é‡ç­–ç•¥ï¼š
// 1) ä¼˜å…ˆåŸºäº responseID å»é‡ï¼š
//   - å¦‚æœæœ¬æ¬¡äº‹ä»¶åŒ…å«éç©ºçš„ responseIDï¼Œä¸”ä¸ä¸Šä¸€æ¬¡è®°å½•çš„ lastASRResponseID ç›¸åŒï¼Œ
//     åˆ™è®¤ä¸ºæ˜¯åŒä¸€æ¬¡ response çš„é‡å¤å®Œæˆäº‹ä»¶ï¼Œç›´æ¥è¿”å› trueï¼ˆä¸¢å¼ƒï¼‰ã€‚
//   - å¦åˆ™å°† lastASRResponseID æ›´æ–°ä¸ºå½“å‰ responseIDï¼ŒåŒæ—¶æ›´æ–° lastASRTranscript/lastASRTranscriptAt
//     ä¸ºå½“å‰ transcript ä¸æ—¶é—´ï¼Œå¹¶è¿”å› falseï¼ˆä¸ä¸¢å¼ƒï¼‰ã€‚
//     è¯´æ˜ï¼šresponseID æ˜¯æœ€å¯é çš„å»é‡é”®ï¼Œå› ä¸ºåŒä¸€ä¸ª response çš„ä¸åŒå®Œæˆäº‹ä»¶ï¼ˆä¾‹å¦‚ audio_transcript.done
//     ä¸ response.doneï¼‰é€šå¸¸ä¼šå¸¦ç›¸åŒçš„ response idã€‚
//
// 2) å½“ responseID ä¸å¯ç”¨æ—¶ï¼Œå›é€€åˆ°åŸºäº transcript å†…å®¹çš„æ—¶é—´çª—å£å»é‡ï¼š
//   - å¦‚æœæœ¬æ¬¡äº‹ä»¶çš„ transcript ä¸ä¸Šä¸€æ¬¡è®°å½•çš„ lastASRTranscript å®Œå…¨ç›¸åŒï¼Œä¸”è·ç¦»ä¸Šæ¬¡è®°å½•æ—¶é—´
//     lastASRTranscriptAt ä¸è¶…è¿‡ asrDuplicateWindowï¼ˆ2 ç§’ï¼‰ï¼Œåˆ™è®¤ä¸ºæ˜¯é‡å¤è½¬å†™ï¼Œè¿”å› trueï¼ˆä¸¢å¼ƒï¼‰ã€‚
//   - å¦åˆ™å°† lastASRTranscript ä¸ lastASRTranscriptAt æ›´æ–°ä¸ºå½“å‰å€¼å¹¶è¿”å› falseï¼ˆä¸ä¸¢å¼ƒï¼‰ã€‚
//
// äº’æ–¥ä¸å¹¶å‘ï¼š
//   - å‡½æ•°å†…éƒ¨ä½¿ç”¨ g.asrDedupMu ä¿æŠ¤å¯¹ lastASRResponseID/lastASRTranscript/lastASRTranscriptAt çš„è¯»å†™ï¼Œ
//     ç¡®ä¿åœ¨å¹¶å‘ ASR äº‹ä»¶åˆ°è¾¾æ—¶ä¸ä¼šå‘ç”Ÿç«æ€æ¡ä»¶ã€‚
//
// è®¾è®¡è€ƒé‡ä¸ä¾‹å­ï¼š
//   - å¸¸è§æƒ…å†µ Aï¼šASR å…ˆå‘é€ response.audio_transcript.doneï¼ˆå« response_idï¼‰ï¼Œéšåå‘é€ response.doneã€‚
//     ä¸¤ä¸ªäº‹ä»¶ä¼šæºå¸¦ç›¸åŒçš„ responseIDï¼ŒåŸºäº responseID çš„å»é‡å¯ä»¥ç›´æ¥è¯†åˆ«å¹¶ä¸¢å¼ƒç¬¬äºŒæ¬¡ã€‚
//   - å¸¸è§æƒ…å†µ Bï¼šæŸäº› ASR å›è°ƒåªåŒ…å« transcript è€Œæ²¡æœ‰ responseIDï¼ˆæˆ– responseID ä¸ºç©ºï¼‰ï¼Œ
//     æ­¤æ—¶ä½¿ç”¨ transcript + æ—¶é—´çª—å£ï¼ˆ2sï¼‰å»é‡èƒ½åœ¨çŸ­æ—¶é—´å†…åˆå¹¶é‡å¤ä¸ŠæŠ¥ï¼Œä½†ä¸ä¼šæ— é™æœŸä¸¢å¼ƒ
//     ä¸å†å²å¾ˆæ—©ä¹‹å‰ç›¸åŒçš„æ–‡æœ¬ã€‚
//   - ä¸ºä»€ä¹ˆä½¿ç”¨æ—¶é—´çª—å£ï¼šçº¯æ–‡æœ¬åŒ¹é…å®¹æ˜“è¯¯åˆ¤ï¼ˆä¸åŒæ—¶é—´çš„ç›¸åŒçŸ­è¯­å¯èƒ½æ˜¯åˆæ³•çš„æ–°è¾“å…¥ï¼‰ï¼Œ
//     å› æ­¤é™åˆ¶åœ¨çŸ­æ—¶é—´çª—å£å†…æ‰è®¤ä¸ºæ˜¯é‡å¤ã€‚
//
// æ³¨æ„ï¼šè¯¥å‡½æ•°åªè´Ÿè´£å†³å®šæ˜¯å¦ä¸¢å¼ƒäº‹ä»¶ï¼›ä¸Šå±‚åœ¨é‡åˆ°ç©º transcript æ—¶å·²æå‰å¿½ç•¥ï¼Œå› æ­¤è¿™é‡Œä¸éœ€è¦
// å¯¹ç©ºæ–‡æœ¬åšé¢å¤–åˆ¤æ–­ï¼ˆä½†ä¿æŒè¦†ç›–æ€§ï¼Œå½“å‰å®ç°ä¹Ÿä¼šæ­£ç¡®å¤„ç†ç©º transcriptï¼‰ã€‚
func (g *MultiVoiceGateway) shouldDropASRResult(responseID string, transcript string) bool {
	g.asrDedupMu.Lock()
	defer g.asrDedupMu.Unlock()

	if responseID != "" {
		if responseID == g.lastASRResponseID {
			return true
		}
		g.lastASRResponseID = responseID
		g.lastASRTranscript = transcript
		g.lastASRTranscriptAt = time.Now()
		return false
	}

	if transcript != "" && transcript == g.lastASRTranscript {
		if time.Since(g.lastASRTranscriptAt) <= asrDuplicateWindow {
			return true
		}
	}

	g.lastASRTranscript = transcript
	g.lastASRTranscriptAt = time.Now()
	return false
}

func (g *MultiVoiceGateway) logRealtimeError(scope string, event map[string]interface{}) {
	raw, err := json.Marshal(event)
	if err != nil {
		g.logger.Printf("[MultiVoiceGateway] %s error payload marshal failed: %v", scope, err)
		return
	}

	g.logger.Printf("[MultiVoiceGateway] %s error payload: %s", scope, string(raw))

	if errObj, ok := event["error"].(map[string]interface{}); ok {
		g.logger.Printf("[MultiVoiceGateway] %s error detail: type=%v code=%v message=%v",
			scope,
			errObj["type"],
			errObj["code"],
			errObj["message"],
		)
	}
}

// handleAudioDelta å¤„ç†éŸ³é¢‘å¢é‡
func (g *MultiVoiceGateway) handleAudioDelta(role string, event map[string]interface{}) error {
	delta, _ := event["delta"].(string)
	if delta == "" {
		return nil
	}

	// éŸ³é¢‘é—¸é—¨ï¼šç”¨æˆ·å¼€å£/æ’è¯åï¼Œç«‹å³åœæ­¢è½¬å‘å½“å‰ speaker çš„éŸ³é¢‘ï¼Œç¡®ä¿â€œç«‹åˆ»æ‰“æ–­â€çš„ä½“éªŒã€‚
	if g.isRoleAudioMuted(role) {
		return nil
	}

	// è§£ç  Base64
	audioData, err := base64.StdEncoding.DecodeString(delta)
	if err != nil {
		return fmt.Errorf("decode audio delta: %w", err)
	}

	// è½¬å‘ç»™å®¢æˆ·ç«¯ï¼ˆä½œä¸ºäºŒè¿›åˆ¶æ¶ˆæ¯ï¼‰
	g.clientConnLock.Lock()
	defer g.clientConnLock.Unlock()

	if err := g.clientConn.WriteMessage(websocket.BinaryMessage, audioData); err != nil {
		return fmt.Errorf("write audio to client: %w", err)
	}

	return nil
}

// handleResponseDone å¤„ç†å“åº”å®Œæˆäº‹ä»¶
func (g *MultiVoiceGateway) handleResponseDone(role string, event map[string]interface{}) error {
	g.logger.Printf("[MultiVoiceGateway] Role %s response done", role)

	// æå– responseID
	response, _ := event["response"].(map[string]interface{})
	responseID, _ := response["id"].(string)

	// å¿…é¡»åœ¨ unregister ä¹‹å‰æ‹å¿«ç…§ï¼Œå¦åˆ™ assistant_text ä¼šä¸¢å¤± beat/sequence ç­‰ä¸Šä¸‹æ–‡ã€‚
	metadata := g.snapshotActiveMetadata(role)

	// æ¸…é™¤æ´»è·ƒå“åº”
	conn, _ := g.voicePool.GetRoleConn(g.ctx, role)
	if conn != nil {
		conn.ClearActiveResponse()
	}

	// æ¸…é™¤æ­£åœ¨è¯´è¯çš„è§’è‰²
	g.voicePool.ClearSpeakingRole()
	g.unmuteRoleAudio(role)

	// æ³¨é”€å…ƒæ•°æ®
	if responseID != "" {
		g.metadataRegistry.Unregister(responseID)
		g.logger.Printf("[MultiVoiceGateway] âœ… Unregistered metadata for responseID=%s", responseID)
	}

	// æå–æœ€ç»ˆæ–‡æœ¬
	output, _ := response["output"].([]interface{})

	var finalText string
	for _, item := range output {
		itemMap, _ := item.(map[string]interface{})
		itemType, _ := itemMap["type"].(string)
		if itemType == "message" {
			content, _ := itemMap["content"].([]interface{})
			for _, c := range content {
				cMap, _ := c.(map[string]interface{})
				if cMap["type"] == "text" {
					text, _ := cMap["text"].(string)
					finalText += text
				} else if cMap["type"] == "audio" {
					transcript, _ := cMap["transcript"].(string)
					finalText += transcript
				}
			}
		}
	}

	if finalText != "" {
		g.logger.Printf("[MultiVoiceGateway] Role %s final text: %s", role, finalText)

		// åŒæ­¥åˆ°æ‰€æœ‰å…¶ä»–è§’è‰²è¿æ¥ï¼ˆæ–‡æœ¬é•œåƒï¼‰
		if err := g.voicePool.SyncAssistantText(finalText, role); err != nil {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸  Failed to sync assistant text: %v", err)
		}

		// å°†æœ€ç»ˆæ–‡æœ¬å‘ç»™å‰ç«¯ï¼ˆç”¨äº UI æ°”æ³¡/å­—å¹•ï¼‰å¹¶å›çŒç»™ Orchestratorï¼ˆç”¨äº SessionState å½’çº¦ï¼Œæ”¯æ’‘è§’è‰²è½®è½¬ï¼‰ã€‚
		_ = g.sendToClient(&ServerMessage{
			Type:     EventTypeAssistantText,
			Text:     finalText,
			Metadata: metadata,
			ServerTS: time.Now(),
		})

		_ = g.forwardToOrchestrator(&ClientMessage{
			Type:     EventTypeAssistantText,
			EventID:  fmt.Sprintf("assistant_%d", time.Now().UnixNano()),
			Text:     finalText,
			Metadata: metadata,
			ClientTS: time.Now(),
		})
	}

	g.notifySpeechEnded(speechEnded{
		role:       role,
		responseID: responseID,
		cancelled:  false,
		endedAt:    time.Now(),
	})

	return nil
}

// sendTTSInterruptedToClient å‘é€ TTS ä¸­æ–­äº‹ä»¶ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendTTSInterruptedToClient(reason string) {
	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending tts_interrupted to client: reason=%s", reason)
	_ = g.sendToClient(&ServerMessage{
		Type:     EventTypeTTSInterrupted,
		Metadata: map[string]interface{}{"reason": reason},
		ServerTS: time.Now(),
	})
}

// muteActiveSpeakerAudio é™éŸ³å½“å‰æ­£åœ¨è¯´è¯çš„è§’è‰²éŸ³é¢‘
func (g *MultiVoiceGateway) muteActiveSpeakerAudio(reason string) {
	if g.voicePool == nil {
		return
	}
	role := g.voicePool.GetSpeakingRole()
	if role == "" {
		return
	}
	g.muteRoleAudio(role, reason)
}

// muteRoleAudio é™éŸ³æŒ‡å®šè§’è‰²çš„éŸ³é¢‘è¾“å‡º
func (g *MultiVoiceGateway) muteRoleAudio(role string, reason string) {
	if role == "" {
		return
	}
	g.audioGateMu.Lock()
	g.mutedRole = role
	g.mutedAt = time.Now()
	g.mutedReason = reason
	g.audioGateMu.Unlock()
}

// unmuteRoleAudio å–æ¶ˆé™éŸ³æŒ‡å®šè§’è‰²çš„éŸ³é¢‘è¾“å‡º
func (g *MultiVoiceGateway) unmuteRoleAudio(role string) {
	g.audioGateMu.Lock()
	if g.mutedRole == role {
		g.mutedRole = ""
		g.mutedAt = time.Time{}
		g.mutedReason = ""
	}
	g.audioGateMu.Unlock()
}

// isRoleAudioMuted æ£€æŸ¥æŒ‡å®šè§’è‰²æ˜¯å¦è¢«é™éŸ³
func (g *MultiVoiceGateway) isRoleAudioMuted(role string) bool {
	g.audioGateMu.Lock()
	muted := g.mutedRole == role && role != ""
	g.audioGateMu.Unlock()
	return muted
}

// snapshotActiveMetadata è·å–è§’è‰²çš„æœ€æ–°å“åº”å…ƒæ•°æ®
func (g *MultiVoiceGateway) snapshotActiveMetadata(role string) map[string]interface{} {
	// ä»æ³¨å†Œè¡¨è·å–è¯¥è§’è‰²çš„æœ€æ–°å…ƒæ•°æ®
	if rm, ok := g.metadataRegistry.GetByRole(role); ok {
		metadata := make(map[string]interface{})
		for k, v := range rm.Metadata {
			metadata[k] = v
		}
		// ç¡®ä¿åŒ…å« role
		metadata["role"] = role
		return metadata
	}

	// é™çº§ï¼šå¦‚æœæ³¨å†Œè¡¨ä¸­æ²¡æœ‰ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
	return map[string]interface{}{
		"role": role,
	}
}

// SendInstructions å‘é€æŒ‡ä»¤åˆ°æŒ‡å®šè§’è‰²çš„è¿æ¥
func (g *MultiVoiceGateway) SendInstructions(ctx context.Context, instructions string, metadata map[string]interface{}) error {
	// ä» metadata ä¸­æå–è§’è‰²
	role, ok := metadata["role"].(string)
	if !ok || role == "" {
		g.logger.Printf("[MultiVoiceGateway] âŒ role not specified in metadata: %+v", metadata)
		return fmt.Errorf("role not specified in metadata")
	}
	if _, exists := g.config.RoleProfiles[role]; !exists {
		return fmt.Errorf("unknown role: %s", role)
	}

	g.logger.Printf("[MultiVoiceGateway] Enqueue instructions to role %s (len=%d)", role, len(instructions))
	g.logger.Printf("[MultiVoiceGateway] Metadata: %+v", metadata)

	// å…¥é˜Ÿå‘è¨€è¯·æ±‚
	// è¯´æ˜ï¼šè¿™é‡Œä¸ç›´æ¥è°ƒç”¨ CreateResponseï¼Œè€Œæ˜¯å…¥é˜Ÿç­‰å¾… speechLoop å¤„ç†ï¼Œ
	// ä»¥ä¿è¯ä»»æ„æ—¶åˆ»åªæœ‰ä¸€ä¸ªè§’è‰²åœ¨è¯´è¯ï¼Œé¿å…éŸ³é¢‘äº¤é”™ã€‚
	// åŒæ—¶ä¹Ÿé¿å…é˜»å¡ Orchestrator çš„äº‹ä»¶å¤„ç†ã€‚
	// æ³¨æ„ï¼šè¿™é‡Œå¯¹ metadata åšæµ…æ‹·è´ï¼Œé˜²æ­¢åç»­å¤–éƒ¨ä¿®æ”¹å½±å“é˜Ÿåˆ—ä¸­çš„æ•°æ®ã€‚
	g.enqueueSpeech(role, instructions, metadata)
	g.speechLoopOnce.Do(func() { go g.speechLoop() })

	// é‡è¦ï¼šè¿™é‡Œä¸é˜»å¡ Orchestratorï¼ˆå¦åˆ™ EventQueue ä¼šå †ç§¯ï¼Œå¯¼è‡´ç”¨æˆ·è½¬å†™/æ’è¯å»¶è¿Ÿå˜å¤§ï¼‰ã€‚
	_ = ctx
	return nil
}

// sendToClient å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendToClient(msg *ServerMessage) error {
	g.seqLock.Lock()
	g.seqCounter++
	msg.Seq = g.seqCounter
	g.seqLock.Unlock()

	data, err := json.Marshal(msg)
	if err != nil {
		return fmt.Errorf("marshal server message: %w", err)
	}

	g.clientConnLock.Lock()
	defer g.clientConnLock.Unlock()

	return g.clientConn.WriteMessage(websocket.TextMessage, data)
}

// sendErrorToClient å‘é€é”™è¯¯æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendErrorToClient(errMsg string) {
	_ = g.sendToClient(&ServerMessage{
		Type:     "error",
		Error:    errMsg,
		ServerTS: time.Now(),
	})
}

// sendTTSStartedToClient å‘é€ TTS å¼€å§‹äº‹ä»¶ç»™å®¢æˆ·ç«¯ï¼ˆåŒ…å«è§’è‰²ä¿¡æ¯ï¼‰
func (g *MultiVoiceGateway) sendTTSStartedToClient(role string) {
	metadata := g.snapshotActiveMetadata(role)

	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending tts_started to client: role=%s", role)

	_ = g.sendToClient(&ServerMessage{
		Type:     "tts_started",
		Metadata: metadata,
		ServerTS: time.Now(),
	})
}

// sendTTSCompletedToClient å‘é€ TTS å®Œæˆäº‹ä»¶ç»™å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) sendTTSCompletedToClient(role string) {
	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending tts_completed to client: role=%s", role)

	_ = g.sendToClient(&ServerMessage{
		Type: "tts_completed",
		Metadata: map[string]interface{}{
			"role": role,
		},
		ServerTS: time.Now(),
	})
}

// SendQuizToClient å‘é€é€‰æ‹©é¢˜åˆ°å®¢æˆ·ç«¯
func (g *MultiVoiceGateway) SendQuizToClient(quizID, question string, options []string, context string) error {
	g.logger.Printf("[MultiVoiceGateway] ğŸ“¤ Sending quiz to client: quiz_id=%s", quizID)

	msg := &ServerMessage{
		Type: EventTypeQuizShow,
		QuizData: &QuizMessageData{
			QuizID:   quizID,
			Question: question,
			Options:  options,
			Context:  context,
		},
		ServerTS: time.Now(),
	}

	return g.sendToClient(msg)
}

// Close å…³é—­ç½‘å…³
func (g *MultiVoiceGateway) Close() error {
	g.logger.Printf("[MultiVoiceGateway] Closing gateway for session %s", g.sessionID)

	g.closeOnce.Do(func() {
		g.cancel()
		close(g.closeChan)

		// å”¤é†’ speechLoopï¼Œé¿å… cond.Wait é€ æˆ goroutine æ³„éœ²ã€‚
		g.speechMu.Lock()
		g.speechCond.Broadcast()
		g.speechMu.Unlock()

		// å…³é—­äº‹ä»¶é˜Ÿåˆ—ï¼ˆç­‰å¾…æ‰€æœ‰å¾…å¤„ç†äº‹ä»¶å®Œæˆï¼‰
		if g.eventQueue != nil {
			stats := g.eventQueue.GetStats()
			g.logger.Printf("[MultiVoiceGateway] Event queue stats: %+v", stats)
			if err := g.eventQueue.Close(); err != nil {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸  Error closing event queue: %v", err)
			}
		}

		// æ¸…ç†å…ƒæ•°æ®æ³¨å†Œè¡¨
		if g.metadataRegistry != nil {
			g.metadataRegistry.Clear()
			g.logger.Printf("[MultiVoiceGateway] âœ… Metadata registry cleared")
		}

		// å…³é—­éŸ³è‰²æ± 
		if g.voicePool != nil {
			_ = g.voicePool.Close()
		}

		// å…³é—­å®¢æˆ·ç«¯è¿æ¥
		g.clientConnLock.Lock()
		if g.clientConn != nil {
			_ = g.clientConn.Close()
		}
		g.clientConnLock.Unlock()
	})

	return nil
}

// Done è¿”å›ä¸€ä¸ªåœ¨è¿æ¥å…³é—­æ—¶å…³é—­çš„ channel
func (g *MultiVoiceGateway) Done() <-chan struct{} {
	return g.closeChan
}

// enqueueSpeech å°†ä¸€æ¬¡â€œå‘è¨€è¯·æ±‚â€å°è£…å¹¶æ”¾å…¥å†…éƒ¨çš„å‘è¨€é˜Ÿåˆ—ï¼ˆéé˜»å¡ï¼‰ã€‚
// ç›®çš„ä¸è®¾è®¡è¯´æ˜ï¼š
//  1. ä¸ç›´æ¥è§¦å‘ç½‘ç»œæˆ–æ¨¡å‹è¯·æ±‚ï¼ˆCreateResponseï¼‰ï¼Œè€Œæ˜¯ä»…æŠŠæŒ‡ä»¤å…¥é˜Ÿã€‚
//     è¿™æ˜¯ä¸ºäº†ä¿æŒ Orchestrator çš„äº‹ä»¶å¤„ç†ï¼ˆSendInstructions è°ƒç”¨ï¼‰è¿…é€Ÿè¿”å›ï¼Œ
//     é˜²æ­¢äº‹ä»¶é˜Ÿåˆ—ï¼ˆEventQueueï¼‰è¢«é˜»å¡æˆ–å †ç§¯ï¼Œå°¤å…¶åœ¨æ¨¡å‹æ‹¨å·/åˆå§‹åŒ–æ…¢æ—¶ã€‚
//  2. ä½¿ç”¨ç‹¬ç«‹çš„ speechLoop æ¥ä¸²è¡Œè§¦å‘å®é™…çš„ CreateResponseï¼Œä¿è¯ä»»æ„
//     æ—¶åˆ»æœ€å¤šåªæœ‰ä¸€ä¸ªè§’è‰²åœ¨åˆæˆ/æ’­æ”¾éŸ³é¢‘ï¼ˆé¿å…éŸ³é¢‘äº¤é”™ï¼‰ã€‚
//  3. åœ¨å…¥é˜Ÿæ—¶å¯¹ metadata åšæµ…æ‹·è´ï¼ˆcloneMetadataï¼‰ï¼Œé¿å…åç»­å¤–éƒ¨ä¿®æ”¹å½±å“é˜Ÿåˆ—ä¸­çš„æ•°æ®ã€‚
//  4. é€šè¿‡ cond.Signal å”¤é†’ç­‰å¾…çš„ speechLoopï¼Œä»¥ä¾¿å°½å¿«å¤„ç†æ–°å…¥é˜Ÿçš„å‘è¨€è¯·æ±‚ã€‚
func (g *MultiVoiceGateway) enqueueSpeech(role string, instructions string, metadata map[string]interface{}) {
	req := speechRequest{
		role:         role,
		instructions: instructions,
		metadata:     cloneMetadata(metadata),
		enqueuedAt:   time.Now(),
	}

	g.speechMu.Lock()
	g.speechQueue = append(g.speechQueue, req)
	queueSize := len(g.speechQueue)
	g.speechMu.Unlock()

	g.logger.Printf("[MultiVoiceGateway] ğŸ™ï¸ Speech enqueued: role=%s queue_size=%d", role, queueSize)
	// å”¤é†’å¯èƒ½æ­£åœ¨ç­‰å¾…é˜Ÿåˆ—çš„ speechLoop
	g.speechCond.Signal()
}

// dropPendingSpeech ä¸¢å¼ƒæ‰€æœ‰å°šæœªè¢« speechLoop å¤„ç†çš„å‘è¨€è¯·æ±‚ã€‚
// ç›®çš„ä¸è®¾è®¡è¯´æ˜ï¼š
//   - åœ¨å‘ç”Ÿæ’è¯ï¼ˆbarge-inï¼‰ã€ASR ç”¨æˆ·å¼€å£æˆ–å…¶å®ƒéœ€è¦ç«‹å³ä¸­æ–­åç»­æ’­æŠ¥çš„åœºæ™¯æ—¶ï¼Œ
//     æˆ‘ä»¬å¸Œæœ›æ¸…é™¤è¿‡æœŸæˆ–ä¸å†é€‚ç”¨çš„å¾…æ’­æŒ‡ä»¤ï¼Œé¿å…æ—§çš„ã€ä¸å½“å‰ä¼šè¯çŠ¶æ€ä¸ä¸€è‡´çš„æ–‡æœ¬è¢«æ’­æŠ¥ã€‚
//   - æ­¤æ“ä½œåªå½±å“â€œé˜Ÿåˆ—ä¸­è¿˜æ²¡å¼€å§‹æ‰§è¡Œâ€çš„è¯·æ±‚ï¼Œä¸ä¼šç›´æ¥å–æ¶ˆå·²ç»å¼€å§‹çš„ responseï¼›
//     å·²å¼€å§‹çš„ response ç”± voicePool.CancelCurrentResponse æ¥å–æ¶ˆã€‚
//   - ä½¿ç”¨æ­¤å‡½æ•°æ—¶é€šå¸¸ä¼šä¼´éšä¸€æ¬¡ CancelCurrentResponse æˆ–å…¶ä»–æ§åˆ¶åŠ¨ä½œï¼Œä»¥æ”¶æ•›ç³»ç»ŸçŠ¶æ€ã€‚
func (g *MultiVoiceGateway) dropPendingSpeech(reason string) {
	g.speechMu.Lock()
	dropped := len(g.speechQueue)
	// æ¸…ç©ºåˆ‡ç‰‡ä½†ä¿ç•™åº•å±‚å®¹é‡ï¼Œé¿å…é¢‘ç¹çš„å†…å­˜åˆ†é…ã€‚
	g.speechQueue = g.speechQueue[:0]
	g.speechMu.Unlock()

	if dropped > 0 {
		g.logger.Printf("[MultiVoiceGateway] ğŸ§¹ Dropped pending speech: dropped=%d reason=%s", dropped, reason)
	}
}

// notifySpeechEnded å‘å†…éƒ¨çš„ speechEndedCh å‘é€å‘è¨€ç»“æŸäº‹ä»¶ï¼Œç”¨äºå”¤é†’æ­£åœ¨ç­‰å¾…çš„ speechLoop æˆ–å…¶ä»–ç­‰å¾…è€…ã€‚
// è®¾è®¡è¯´æ˜ï¼š
//   - speechEndedCh æ˜¯ä¸€ä¸ªå¸¦ç¼“å†²çš„ channelï¼ˆå®¹é‡æœ‰é™ï¼‰ï¼Œç”¨äºåœ¨ response.done / response.cancelled
//     ç­‰äº‹ä»¶åˆ°æ¥æ—¶é€šçŸ¥é˜Ÿåˆ—æ¨è¿›ã€‚è¿™é‡Œä½¿ç”¨éé˜»å¡å‘é€ï¼ˆselect defaultï¼‰ä»¥é¿å…åœ¨æç«¯æƒ…å†µä¸‹
//     é˜»å¡äº‹ä»¶å¤„ç† goroutineï¼ˆä¾‹å¦‚å½“æ²¡äººæ¶ˆè´¹æ—¶ï¼‰ã€‚
//   - ä¸¢å¼ƒé€šçŸ¥ä¸ä¼šå½±å“ç³»ç»Ÿæ­£ç¡®æ€§ï¼šå¦‚æœé€šçŸ¥è¢«ä¸¢å¼ƒï¼ŒspeechLoop ä¼šåœ¨è¶…æ—¶åé€šè¿‡è¶…æ—¶æœºåˆ¶æ¨è¿›ã€‚
//   - è¿™ç§è®¾è®¡æƒè¡¡äº†å¯é æ€§ï¼ˆå°½é‡ä¼ é€’äº‹ä»¶ï¼‰ä¸å¯ç”¨æ€§ï¼ˆä¸å› æœªæ¶ˆè´¹é€šçŸ¥é˜»å¡å…³é”®è·¯å¾„ï¼‰ã€‚
func (g *MultiVoiceGateway) notifySpeechEnded(ev speechEnded) {
	select {
	case g.speechEndedCh <- ev:
	default:
		// ä»…ç”¨äºé©±åŠ¨é˜Ÿåˆ—æ¨è¿›ï¼Œä¸¢å¼ƒä¸ä¼šå½±å“ç³»ç»Ÿæ­£ç¡®æ€§ï¼ˆæœ€åæƒ…å†µï¼šç”±è¶…æ—¶å…œåº•æ¨è¿›ï¼‰ã€‚
	}
}

// speechLoop æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„åç¨‹ï¼Œè´Ÿè´£ä»å‘è¨€é˜Ÿåˆ—ä¸­å–å‡ºè¯·æ±‚å¹¶ä¾æ¬¡æ‰§è¡Œã€‚
// è®¾è®¡è¦ç‚¹ï¼š
// - ä¿è¯ä»»æ„æ—¶åˆ»åªæœ‰ä¸€ä¸ªè§’è‰²åœ¨è¯´è¯ï¼Œé¿å…éŸ³é¢‘äº¤é”™ã€‚
// - ä½¿ç”¨æ¡ä»¶å˜é‡ä¸äº’æ–¥é”é…åˆï¼Œé¿å…å¿™ç­‰å¾…å¹¶èƒ½åœ¨æ–°è¯·æ±‚åˆ°æ¥æ—¶è¿…é€Ÿå”¤é†’ã€‚
// - åœ¨æ‰§è¡Œ CreateResponse å‰åå¤„ç†å¹¶å‘è¯´è¯çš„é˜²å¾¡é€»è¾‘ï¼Œç¡®ä¿ç³»ç»ŸçŠ¶æ€æ”¶æ•›ã€‚
func (g *MultiVoiceGateway) speechLoop() {
	// ç­‰å¾… voicePool å°±ç»ªï¼ˆStart ä¹‹åï¼‰ã€‚
	select {
	case <-g.voicePoolReady:
	case <-g.closeChan:
		return
	}

	const maxWaitSpeechEnd = 6 * time.Minute

	for {
		// ä»å‘è¨€é˜Ÿåˆ—ä¸­å–å‡ºä¸‹ä¸€ä¸ªè¯·æ±‚ï¼ˆé˜»å¡ç›´åˆ°æœ‰è¯·æ±‚æˆ–ç½‘å…³å…³é—­ï¼‰ã€‚
		req, ok := g.nextSpeechRequest()
		if !ok {
			return
		}

		// é˜²å¾¡ï¼šå¦‚æœå¤–éƒ¨è·¯å¾„æ„å¤–è§¦å‘äº†å¹¶å‘è¯´è¯ï¼Œè¿™é‡Œå…ˆç­‰ä¸Šä¸€æ®µç»“æŸ/æˆ–è¶…æ—¶å–æ¶ˆã€‚
		if g.voicePool != nil && g.voicePool.GetSpeakingRole() != "" {
			g.logger.Printf("[MultiVoiceGateway] âš ï¸  Speech loop found active speaker, waiting... active_role=%s",
				g.voicePool.GetSpeakingRole())
			_ = g.waitAnySpeechEnded(maxWaitSpeechEnd)
		}

		// roleConn å¯èƒ½æ˜¯æŒ‰éœ€åˆ›å»ºçš„ï¼Œé¦–æ¬¡åˆ›å»ºä¼šç»å†æ‹¨å·/æ¡æ‰‹/åˆå§‹åŒ–ã€‚
		// è¿™é‡Œçš„è¶…æ—¶è¦è¦†ç›– roleConnCreateTimeoutï¼Œé¿å…â€œé˜Ÿåˆ—ä¸€ç›´é‡è¯•ä½†æ°¸è¿œèµ·ä¸æ¥â€çš„æŠ–åŠ¨ã€‚
		reqCtx, cancel := context.WithTimeout(g.ctx, roleConnCreateTimeout+15*time.Second)
		err := g.voicePool.CreateResponse(reqCtx, req.role, req.instructions, req.metadata)
		cancel()
		if err != nil {
			// å¦‚æœæ˜¯â€œæœ‰äººåœ¨è¯´è¯â€ï¼ŒæŠŠå®ƒé‡æ–°å¡å›é˜Ÿåˆ—å°¾éƒ¨ï¼›å¦åˆ™ä¸¢å¼ƒå¹¶ç»§ç»­ã€‚
			if errors.Is(err, ErrRoleAlreadySpeaking) {
				g.logger.Printf("[MultiVoiceGateway] âš ï¸  Speech blocked by active speaker, requeue: role=%s err=%v", req.role, err)
				g.enqueueSpeech(req.role, req.instructions, req.metadata)
				_ = g.waitAnySpeechEnded(maxWaitSpeechEnd)
				continue
			}

			g.logger.Printf("[MultiVoiceGateway] âŒ Failed to start speech: role=%s err=%v", req.role, err)
			continue
		}

		// ç­‰å¾…æœ¬æ¬¡æ’­æŠ¥ç»“æŸï¼ˆdone/cancelledï¼‰ã€‚
		timer := time.NewTimer(maxWaitSpeechEnd)
		for {
			select {
			case <-g.closeChan:
				timer.Stop()
				return

			case ev := <-g.speechEndedCh:
				// ç†è®ºä¸Šåªæœ‰ä¸€ä¸ª speakerï¼›å¦‚æœå‡ºç°ä¸ä¸€è‡´ï¼Œè®°å½•åä»æ¨è¿›ï¼Œé¿å…é˜Ÿåˆ—å¡æ­»ã€‚
				if ev.role != "" && ev.role != req.role {
					g.logger.Printf("[MultiVoiceGateway] âš ï¸  Unexpected speech ended: got_role=%s want_role=%s resp=%s cancelled=%v",
						ev.role, req.role, ev.responseID, ev.cancelled)
				}

				timer.Stop()
				goto next

			case <-timer.C:
				// å…œåº•ï¼šé¿å… roleConn å¼‚å¸¸å¯¼è‡´é˜Ÿåˆ—æ°¸ä¹…å¡æ­»ã€‚
				g.logger.Printf("[MultiVoiceGateway] â±ï¸ Speech end timeout, force cancel: role=%s", req.role)
				_ = g.voicePool.CancelCurrentResponse()
				goto next
			}
		}
	next:
		continue
	}
}

// nextSpeechRequest ä»å‘è¨€é˜Ÿåˆ—ä¸­å–å‡ºä¸‹ä¸€ä¸ªè¯·æ±‚ï¼ˆé˜»å¡ç›´åˆ°æœ‰è¯·æ±‚æˆ–ç½‘å…³å…³é—­ï¼‰ã€‚
// è®¾è®¡è¦ç‚¹ï¼š
// - ä½¿ç”¨ g.speechCond æ¡ä»¶å˜é‡ä¸ g.speechMu äº’æ–¥é”é…åˆï¼Œé¿å…å¿™ç­‰å¾…å¹¶èƒ½åœ¨æ–°è¯·æ±‚åˆ°æ¥æ—¶è¿…é€Ÿå”¤é†’ã€‚
// - è¿”å›å€¼ç¬¬äºŒä¸ªå¸ƒå°”ä½è¡¨ç¤ºæˆåŠŸå–åˆ°è¯·æ±‚ï¼ˆtrueï¼‰æˆ–å› ç½‘å…³å…³é—­è€Œé€€å‡ºï¼ˆfalseï¼‰ã€‚
// - ä»é˜Ÿåˆ—å¤´ç§»é™¤å…ƒç´ æ—¶é‡‡ç”¨ä¸¤æ­¥ï¼šå…ˆ copy å‰ç§»ï¼Œå†ç¼©çŸ­åˆ‡ç‰‡é•¿åº¦ï¼Œä»¥é¿å…å†…å­˜æ³„éœ²æˆ–ä¿ç•™å·²ç”¨å…ƒç´ çš„å¼•ç”¨ã€‚
func (g *MultiVoiceGateway) nextSpeechRequest() (speechRequest, bool) {
	g.speechMu.Lock()
	defer g.speechMu.Unlock()

	for len(g.speechQueue) == 0 {
		// ç­‰å¾…ç›´åˆ°æœ‰æ–°çš„å‘è¨€è¢«å…¥é˜Ÿæˆ–ç½‘å…³å…³é—­
		g.speechCond.Wait()
		select {
		case <-g.closeChan:
			return speechRequest{}, false
		default:
		}
	}

	// å–å‡ºé˜Ÿé¦–å…ƒç´ å¹¶å°†åˆ‡ç‰‡å‰ç§»
	req := g.speechQueue[0]
	copy(g.speechQueue, g.speechQueue[1:])
	g.speechQueue = g.speechQueue[:len(g.speechQueue)-1]
	return req, true
}

// waitAnySpeechEnded ç­‰å¾…ä»»æ„ä¸€æ¬¡å‘è¨€ç»“æŸäº‹ä»¶æˆ–è¶…æ—¶ã€‚
// è®¾è®¡è¦ç‚¹ï¼š
// - è¯¥å‡½æ•°é€šå¸¸ç”¨äºåœ¨å°è¯•å‘èµ·æ–°å‘è¨€å‰ï¼Œç¡®ä¿ä¸Šä¸€ä¸ªå‘è¨€å·²ç»ç»“æŸï¼Œé¿å…å¹¶å‘å‘è¨€ã€‚
// - ä½¿ç”¨å¸¦è¶…æ—¶çš„ timer ä½œä¸ºå…œåº•ï¼Œé˜²æ­¢å› äº‹ä»¶æœªåˆ°è¾¾å¯¼è‡´æ°¸ä¹…é˜»å¡ï¼ˆä¾‹å¦‚ roleConn å´©æºƒï¼‰ã€‚
// - å¦‚æœç½‘å…³æ­£åœ¨å…³é—­ï¼ˆg.closeChan å…³é—­ï¼‰ï¼Œä¼˜å…ˆè¿”å› context.Canceledï¼Œä»¥ä¾¿è°ƒç”¨æ–¹åŠæ—¶ä¸­æ­¢ã€‚
func (g *MultiVoiceGateway) waitAnySpeechEnded(timeout time.Duration) error {
	timer := time.NewTimer(timeout)
	defer timer.Stop()

	select {
	case <-g.closeChan:
		return context.Canceled
	case <-timer.C:
		return context.DeadlineExceeded
	case <-g.speechEndedCh:
		return nil
	}
}

// cloneMetadata æµ…æ‹·è´ metadataï¼Œä»¥é˜²æ­¢å¤–éƒ¨æŒæœ‰çš„ map åœ¨å…¥é˜Ÿåè¢«ä¿®æ”¹ï¼Œé€ æˆä¸å¯é¢„æµ‹çš„è¡Œä¸ºã€‚
// æˆ‘ä»¬ä¸åšæ·±æ‹·è´ï¼Œå› ä¸º metadata çš„å€¼é€šå¸¸æ˜¯ç®€å•ç±»å‹æˆ–å·²çŸ¥çš„å°ç»“æ„ï¼›è‹¥å°†æ¥éœ€è¦æ·±æ‹·è´ï¼Œ
// å¯ä»¥åœ¨æ­¤å¤„æ‰©å±•ã€‚
func cloneMetadata(src map[string]interface{}) map[string]interface{} {
	if src == nil {
		return nil
	}
	dst := make(map[string]interface{}, len(src))
	for k, v := range src {
		dst[k] = v
	}
	return dst
}
