# BubbleTalk 第一阶段技术实现方案（后端 Go Only｜语音原生｜对话一等公民｜可直接开工）

> 本文只描述 **Go 后端**：它如何把“语音对话”变成系统的事实源，如何调度导演状态机与工具，并如何让整条会话可回放、可验收。
>
> 前端（Vue/RTC/录音播放/字幕 UI）请看：`docs/第一阶段前端实现方案（Vue）.md`。

---

## 0. 第一阶段目标与边界

### 0.1 第一阶段要交付什么（MVP-1）

第一阶段交付的是一个“能跑通、可验收”的 **语音对话学习引擎后端**：

1. **固定泡泡列表**（≤10 个，JSON 配置）
2. **会话编排器 Session Orchestrator（核心骨架）**
   - 事件驱动：接收语音/工具事件并归约状态
   - 统一裁决：何时推进主线、何时出题、何时退出
3. **导演状态机 DirectorEngine（核心决策）**
   - 心智状态识别（启发式为主，可选 LLM Router）
   - 插话分类（Clarify/Deepen/Branch/Meta/Off-topic）
   - Beat 选择（候选 + 打分 + 硬约束）
   - 输出动作强制（Output Ladder + OutputClock：90 秒必输出）
4. **演员生成 ActorEngine（表达层）**
   - 生成“台词脚本”（可朗读文本 + 用户动作提示 + fallback）
   - 语音输出由 gpt-realtime 完成，但“导演约束”必须由后端注入并可回放
5. **测评/工具极简（mock 也可）**
   - DIAGNOSE：固定 2 题（可口语化宣读 + 点击答题）
   - EXIT：固定 1 题迁移 + 1 句解释（强制）
6. **Realtime Gateway（语音原生必需）**
   - 客户端只连后端（单一会话通道）
   - 后端直连 gpt-realtime（ASR + TTS）并转发音频/事件
   - 插话中断（barge-in）作为一等事件进入事件流
7. **可回放时间线（Conversation Timeline）**
   - 以事件流为事实源：可审计、可解释、可验收

### 0.2 第一阶段明确不做（允许延后）

- 推荐系统、长期记忆、知识检索（可固定/Mock）
- 多角色同时发言/叠音（第一阶段每次只允许一个主讲角色）
- 复杂语音体验优化（VAD、超低延迟流式 TTS、离线包等）

---

## 1. 核心原则：什么叫“对话一等公民”（Conversation First）

在工程上它不是一句 slogan，而是三条硬约束：

1. **事实源 = 会话事件流（Event Log）**
   - 任何会影响学习推进的输入（语音最终转写、答题、插话、退出）必须进入同一条事件流。
   - `SessionState` 必须由 `reduce(state, event)` 归约得到（可回放、可回归）。
   - 这里的 Event/Timestamp/Seq 不是“为了记日志”，而是为了把系统从“随缘聊天”变成“可证明的状态机”：
     - **崩溃恢复**：只要 Timeline 在，就能回放重建到一致状态（不会出现“说了但没记/记了但没说”）。
     - **幂等与重试**：客户端/网关重试不会导致同一次输入被算两次（靠 `seq` 与 `event_id`）。
     - **验收与审计**：OutputClock/退出必迁移/出题次数等都可以从事件流计算并验收，而不是靠体验主观判断。
     - **调试与迭代**：当某轮对话“像跑偏了”，你能精确定位是哪一个事件触发了哪次决策与输出。
2. **语音优先，但裁决在后端**
   - gpt-realtime 负责 ASR/TTS 等“语音能力”，但 **是否推进、是否出题、是否退出、是否算有效输出** 由后端裁决。
3. **可验收**
   - “每 90 秒必触发一次用户输出动作”“用户说结束必出迁移检验”必须能从时间线中验证，而不是依赖主观体验。

---

## 2. 后端总体架构（组件与关系）

一句话：**Realtime Gateway 把语音变成事件；Orchestrator 用事件驱动 Director/Actor/Assessment；Timeline 支撑回放与验收。**

```
Client (only talks to Backend)
   |
   |  Session Stream (WS or WebRTC-to-backend)
   v
Realtime Gateway  <----->  OpenAI gpt-realtime (ASR/TTS + optional text)
   |
   |  Events (asr_final/quiz_answer/barge_in/...)
   v
Session Orchestrator
   |--> Reducer (state = reduce(state, event))
   |--> DirectorEngine (Decide -> DirectorPlan)
   |--> Guardrails (hard constraints, fix plan)
   |--> Assessment/Tools (quiz/exit ticket)
   |--> ActorEngine (script -> instructions)
   |--> Realtime Gateway (send instructions, stream audio back)
   v
Timeline Store (append-only events) + Session Store (latest snapshot)
```

模块职责在“交互过程中做什么”，请看第 5 节的“端到端时序”。

---

## 3. 数据模型（第一阶段最小但够用）

> 目标：少而强，且所有关键字段都能落到事件流里复盘。

### 3.1 Bubble（入口）

`configs/bubbles.json`

```json
[
  {
    "entry_id": "econ_weekend_overtime",
    "domain": "economics",
    "title": "周末加班到底值不值？",
    "hook": "你以为赚了800，可能亏了更贵的东西。",
    "primary_concept_id": "econ_opportunity_cost"
  }
]
```

### 3.2 SessionState（快照，不是事实源）

`SessionState` 是最新状态快照，用于快速加载；事实源是 Timeline（事件流）。

关键字段（示意）：

```go
type SessionState struct {
  SessionID string
  EntryID   string
  Domain    string

  MainObjective string
  Act           int
  Beat          string
  PacingMode    string

  MasteryEstimate float64
  MisconceptionTags []string

  OutputClockSec int
  LastOutputAt   time.Time

  TensionLevel  int
  CognitiveLoad int

  QuestionStack []BranchQuestion
  Turns         []Turn // 用于 UI 快速渲染，严肃回放以 Timeline 为准
}
```

### 3.3 Event（事实源：统一承载“语音 + 工具 + 控制”）

第一阶段的关键：**语音输入与答题等工具交互必须能混在同一个 API/通道里**，并通过 `seq/turn_id` 形成同一条时间线。

最小事件集合（示意）：

```go
type Event struct {
  Seq      int64
  Type     string // asr_final / quiz_answer / barge_in / exit_requested / ...
  TurnID   string
  ClientTS time.Time
  ServerTS time.Time

  Text       string // asr_final / user_message
  QuestionID string // quiz_answer
  Answer     string // quiz_answer
}
```

约束：

- `Seq` 必须单调递增（由后端分配），用于幂等与回放。
- `asr_partial` 不进入“导演决策事实源”，只作为体验事件（可选落库）。
- “推进决策”的唯一语音输入：`asr_final.text`。

> 常见误解澄清：
> - Timeline/Event 不是“额外的日志系统”，它就是你的“会话数据库”（append-only），SessionState 只是缓存快照。
> - 你越早把“事件先行 + 归约快照”跑通，后面接 Director/Actor/Assessment 才不会变成到处打补丁的 if-else。

### 3.4 DirectorPlan（导演输出：结构化、可校验、可回放）

```go
type DirectorPlan struct {
  UserMindState []string
  Intent        string

  NextBeat     string
  NextRole     string
  OutputAction string // Choice/Recap/Example/Boundary/Feynman/Transfer

  TalkBurstLimitSec int
  InterruptibleAfterMS int

  TensionGoal string
  LoadGoal    string

  StackAction string // keep/push/pop（第一阶段先字符串，后续再结构化）
  Notes       string
}
```

### 3.5 ActorReply（演员输出：脚本，不是自由发挥）

```json
{
  "speech_text": "……（短句、可朗读）",
  "interruptible_after_ms": 800,
  "user_action": { "type": "recap", "prompt": "用一句话复述，必须包含因为…所以…" },
  "quiz": null,
  "fallbacks": ["如果你卡住，就用这个句式：因为____，所以____。"]
}
```

---

## 4. API 设计（后端对外接口：HTTP + 会话通道 + timeline）

### 4.1 基础 HTTP

- `GET /api/bubbles`：固定泡泡列表
- `POST /api/sessions`：创建会话（返回 session_id + 初始快照 + diagnose 题）
- `POST /api/sessions/{id}/events`：文本回退/测试入口（非主路径）

### 4.2 会话通道（唯一主路径：Conversation Bus）

第一阶段建议先用 **WebSocket**（实现成本最低，足够支撑导演闭环）；如果你明确要 RTC，则做“客户端↔后端 WebRTC”。

**方案 A（推荐）：WebSocket**

- `GET /api/sessions/{id}/stream`（WebSocket）
  - 文本帧：JSON 事件（quiz_answer / barge_in / debug_toggle …）
  - 二进制帧：音频数据（Opus/PCM16，帧头携带 codec/seq/ts）

**方案 B（可选）：WebRTC（客户端只连后端）**

- `POST /api/sessions/{id}/rtc/offer`（HTTP：交换 SDP）
  - 音频轨：用户上行 + 系统下行
  - DataChannel：事件与工具交互

通道内必须支持“混合事件”：

- `audio_frame`（语音输入）
- `quiz_answer`（工具输入）
- `barge_in`（控制事件）
- `exit_requested`（退出）

**原则**：对外只暴露一个“会话通道”，让所有交互都在同一时间线里发生。

### 4.3 会话时间线（回放/审计/验收）

- `GET /api/sessions/{id}/timeline?cursor=...`

返回（示意）：

```json
{
  "cursor": "C_...",
  "events": [
    { "seq": 101, "type": "asr_final", "turn_id": "T_1", "text": "...", "ts": "..." },
    { "seq": 102, "type": "director_plan", "turn_id": "T_2", "plan": { "next_beat": "Check", "output_action": "Recap" }, "ts": "..." },
    { "seq": 103, "type": "assistant_text", "turn_id": "T_2", "text": "...", "ts": "..." },
    { "seq": 104, "type": "quiz_answer", "question_id": "diag_q1", "answer": "B", "ts": "..." }
  ]
}
```

---

## 5. 端到端交互：每个模块具体做什么（强结构）

下面用“会话启动 → 测评 → 研讨回合循环 → 退出”描述一次完整交互。你可以把它当作实现时的主线 checklist。

### 5.1 会话启动（用户点击泡泡）

1. API：`POST /api/sessions { entry_id }`
2. Orchestrator：
   - 初始化 SessionState（Act=1、Beat=ColdOpen、OutputClock=0）
   - 写入 timeline：`session_created`
3. Assessment：
   - 生成（或读取固定）DIAGNOSE 题 2 道
   - 写入 timeline：`quiz_delivered`
4. 返回给客户端：session_id + 初始快照 + diagnose

### 5.2 语音输入（用户说话）

1. Client → Gateway：发送音频帧（同一会话通道）
2. Gateway（后端直连 gpt-realtime）：
   - 把音频送入 Realtime
   - 收到 `asr_partial`：转发给客户端（可选落库）
   - 收到 `asr_final`：追加到 timeline（事实源），并触发 Orchestrator 推进

### 5.3 工具交互（用户答题）

1. Client → Gateway：`quiz_answer`
2. Gateway：
   - 追加到 timeline（事实源）
   - 触发 Orchestrator 推进（可能更新 misconception/mastery）

> 这里回答你的问题：**语音输入与答题工具交互混在一个 API/通道里是正确方向**，因为它们都是“会话事件”，必须共享同一时间线与裁决逻辑。

### 5.4 研讨回合（一次推进循环）

触发条件：收到一个“推进事件”（`asr_final` / `quiz_answer` / `exit_requested` 等）

1. Orchestrator：读取快照 + 追加事件（timeline 已有），更新 signals/output_clock
2. DirectorEngine：`Decide(state, last_event, recent_summary) -> DirectorPlan`
3. Guardrails（硬约束修正）：
   - `output_clock_sec >= 90`：强制选择输出类拍点（Check/Feynman/Transfer/Exit）
   - 用户说“我懂了/结束”：强制 ExitTicket（迁移检验）
   - Branch：默认入栈（除非强相关误解，才允许降级为 Deepen）
4. ActorEngine：把 DirectorPlan 编译成“台词脚本 + 用户动作提示”
5. Realtime Gateway：
   - 把本轮脚本/约束注入 Realtime（例如 session.update / response.create）
   - 接收 Realtime 输出的音频与文本：音频流式转发给客户端，文本写入 timeline
6. Orchestrator：写回快照（state），并把 `director_plan` 也写入 timeline（调试期强烈建议保留）

### 5.5 插话中断（barge-in）

1. Client → Gateway：`barge_in`（或“用户开始说话”的控制事件）
2. Gateway：
   - 立刻中断/重置当前 Realtime 输出（避免继续播报造成“压过用户”）
   - 追加 `barge_in` 到 timeline
3. Orchestrator：
   - 将其作为节奏信号输入 Director（例如降低 talk burst、改为提问式、优先 CHECK）

### 5.6 退出与迁移检验（Exit Ticket）

触发条件：

- 用户明确说“结束/我懂了”
- 或导演判定进入 Act III 收束

后端硬约束：

1. Assessment：生成 EXIT 迁移题（固定 1 题 + 1 句解释）
2. Director/Actor：必须引导用户完成迁移作答（语音或点击）
3. timeline：写入 `exit_ticket_delivered`、`exit_ticket_answered`

---

## 6. Director/Actor/Assessment 的实现边界（避免漂移）

第一阶段要坚持一条分工线：

- Director：只做“选择动作/拍点/工具/输出要求”，输出结构化计划（可校验）
- Actor：只做“按计划表达”，输出脚本（可朗读、短句、可打断）
- Assessment：只做“题目与评分”，并把结果写回 state
- gpt-realtime：只做“语音能力 +（可选）受控文本生成”，不直接拥有系统裁决权

导演细节与角色调度建议参考：

- `docs/导演状态机技术实现方案.md`
- `docs/导演如何调度“泡泡角色”.md`
- `docs/附件 A：导演状态机规则集（Director State Machine Rule Set）.md`
