# BubbleTalk 会话编排器技术实现方案（Session Orchestrator｜Go｜语音原生｜对话一等公民）

> 目标：把“用户语音输入 + 工具交互（答题/分叉/退出）+ 系统语音输出”统一为 **一条可回放、可验收的会话事件流**，并在后端用确定性的编排逻辑驱动导演状态机与工具。
>
> 本文只描述后端（Go）会话编排器如何实现。全局后端架构见：`docs/第一阶段技术实现方案.md`。

---

## 1. 会话编排器是什么（定位与边界）

### 1.1 定位：它不是“聊天 API”，而是“会话剪辑台”

会话编排器是系统的“剪辑台/现场助导”，它做三件事：

1. **把输入变成事实**：将语音 ASR final、答题、插话中断、退出请求等转换为带 `seq` 的事件并追加到 Timeline。
2. **把事实变成决策**：以 `reduce(state, event)` 回放/归约状态，构造 DirectorInput，调用 DirectorEngine 得到 DirectorPlan，并用 Guardrails 修正。
3. **把决策变成输出**：调用 ActorEngine 生成“台词脚本”，再通过 Realtime Gateway 驱动 gpt-realtime 生成语音并流式转发，最后把输出写回 Timeline。

一句话：**它负责“拍”，不负责“说”**。说话交给 Actor / gpt-realtime；决定交给 Director；但“系统到底做了什么”必须由编排器落库并可解释。

### 1.2 边界：哪些权力一定不能下放给模型

为了满足“对话一等公民”的可控与可验收，以下裁决必须在后端完成：

- 是否算作一次“有效用户输出动作”（影响 OutputClock 与学习闭环）
- `output_clock_sec >= 90` 时强制触发哪类输出（CHECK/FEYNMAN/TRANSFER/EXIT）
- 用户说“结束/我懂了”时必须触发 Exit Ticket（迁移检验）
- 工具调用（出题/评分/回收分叉栈）是否允许、何时允许、使用哪个模板
- 角色集合（RoleSet）边界：导演只能在泡泡固定角色集合内调度

---

## 2. 编排器要满足的核心不变量（Invariants）

这些不变量决定了系统是否真正“Conversation First”：

1. **Timeline 先行**：任何会影响学习推进的输入/输出都必须先追加到 Timeline，再触发推进逻辑（append-first）。
2. **单会话串行**：同一个 session 的推进必须串行执行（避免计划错位/重复出题/重复播报）。
3. **事件可幂等**：客户端重试、网络抖动、重连，都不能导致“同一次答题被记两次”“同一句助手语音播两次”。
4. **决策可解释**：每次 DirectorPlan 必须写入 Timeline（开发期强制，生产可采样/可开关）。
5. **输出可审计**：assistant 的文本字幕（以及关键音频段 ID/时间戳）必须进入 Timeline，才能做验收统计与回放。

---

## 3. 组件关系与数据流（高层）

```
Client (只连后端一个会话通道)
   |
   |  Session Stream (WS / WebRTC-to-backend)
   v
RealtimeGateway  <----->  OpenAI gpt-realtime (ASR/TTS)
   |                         ^
   | events                  | instructions / cancel
   v                         |
SessionOrchestrator ---------+
   |
   | append events
   v
TimelineStore (append-only) + SnapshotStore (latest SessionState)
```

编排器处在中心：它既接收来自 Gateway 的输入事件，也负责把“导演/演员的指令”送回 Gateway 驱动语音输出。

---

## 4. 核心数据模型（编排器视角）

> 关键点：**编排器只相信事件流**。快照只是缓存。

### 4.1 Event：统一承载“语音 + 工具 + 控制 + 输出”

建议把事件分成两类：

- **事实事件（Fact Events）**：进入学习推进与验收统计的“硬事实”
- **体验事件（UX Events）**：只影响体验，不作为学习事实（可落库但不参与核心裁决）

事实事件最小集合（第一阶段）：

- 输入：
  - `asr_final`（语音最终转写；唯一进入导演决策的语音输入）
  - `user_message`（文字回退）
  - `quiz_answer`（答题）
  - `barge_in`（插话中断）
  - `exit_requested`（退出）
- 输出：
  - `director_plan`（每轮决策的结构化计划）
  - `assistant_text`（字幕）
  - `assistant_audio_started/assistant_audio_ended`（语音输出边界，用于节奏/中断/回放对齐）
  - `quiz_delivered` / `exit_ticket_delivered`

体验事件（可选）：

- `asr_partial`（实时字幕）
- `playback_volume_changed`（客户端侧降音/静音）
- `client_focus_changed`（App 前后台）

建议 Event 统一包含：

- `seq`（后端分配的单调序号，幂等与回放的基石）
- `event_id`（客户端 UUID，可用于去重）
- `turn_id`（将一组事件归属到同一轮：user turn / assistant turn）
- `client_ts/server_ts`

### 4.2 SessionState：快照（cache），必须可由回放重建

`SessionState = Reduce(all_events)`，任何不能从事件流重建的字段都属于风险（会导致回放不一致）。

### 4.3 DirectorInput：导演读取的是“监控面板”，不是全文对话

编排器负责把最近事件归约成结构化摘要，避免把整个对话历史喂给导演造成不稳定。

最小摘要建议包含：

- 当前主目标/幕/拍点
- 最近一次 `asr_final` 文本
- OutputClock、Tension、Load、Fatigue
- 最近一次用户有效输出质量（规则评分）
- 分叉栈深度与待回收问题列表（简化）

---

## 5. 编排器主循环（最重要）

### 5.1 单会话串行模型（推荐：Session Worker / Actor Model）

实现建议：每个 session 一个 worker goroutine，所有事件按顺序进入它的 inbox：

- 优点：天然避免并发错位；代码简单；与“可回放状态机”相容
- 代价：需要做 session 生命周期管理（TTL、并发上限、清理）

抽象接口（示意）：

```go
type Orchestrator interface {
  // OnEvent 接收一个“已标准化”的事件（已分配 seq/ts），并可能产生 0..N 个副作用（如：发送给 Realtime、写回快照）。
  OnEvent(ctx context.Context, sessionID string, evt Event) error
}
```

### 5.2 append-first：事件落库顺序（强制）

收到任何输入事件时，固定顺序：

1. **Normalize**：补齐字段（server_ts、session_id、turn_id…）
2. **AssignSeq**：分配 `seq`（与 TimelineStore 原子化）
3. **Append Timeline**：追加事件
4. **Reduce**：对该事件做状态归约（或对全量回放做增量归约）
5. **Decide/Act**：若该事件触发推进，则进入导演/演员/工具流程

为什么必须 append-first：

- 崩溃恢复时，你只要回放 Timeline 就能恢复到一致状态；
- 任何一次“系统输出”都能被审计，不会出现“说了但没记”或“记了但没说”。

### 5.3 触发推进的事件（Trigger Events）

不是所有事件都需要触发“推进一轮”。第一阶段建议：

触发推进：

- `asr_final`
- `user_message`
- `quiz_answer`
- `exit_requested`

不触发推进（只更新体验/信号）：

- `asr_partial`
- `assistant_audio_started/ended`（通常只更新节奏与可打断状态）

### 5.4 一轮推进的确定性流水线（核心）

当收到 Trigger Event：

**Step 0：加载快照**

- 从 SnapshotStore 取最新 `SessionState`（或缓存于 worker 内存）

**Step 1：Reducer 更新 state**

- `state = reduce(state, evt)`
- 只做“事实归约”，不做任何外部调用

**Step 2：构造 DirectorInput**

- 从 `state + recent events` 生成结构化面板（见 4.3）

**Step 3：导演决策**

- `plan = DirectorEngine.Decide(input)`
- 立即把 `director_plan` 作为事件写入 Timeline（Fact Event）

**Step 4：Guardrails 修正（硬约束优先）**

典型硬约束（第一阶段必须）：

- OutputClock ≥ 90 秒：强制 `plan.output_action` 为输出类（Recap/Choice/Transfer/Feynman）
- 用户“结束/我懂了”（来自 asr_final 或 user_message）：强制 Exit Ticket
- Branch：默认入栈（QuestionStack push），并安排回收策略
- 角色集合：plan.next_role 必须属于该泡泡 RoleSet

**Step 5：工具/测评注入（可选）**

如果 `plan.output_action` 需要题目：

- 调用 AssessmentEngine 生成 quiz（固定题/模板题）
- 写入 `quiz_delivered` 事件

**Step 6：演员脚本生成**

- `reply = ActorEngine.Generate(plan, state, tool_payload)`
- 输出结构必须严格校验（JSON schema / 白名单字段）

**Step 7：驱动语音输出（通过 Realtime Gateway）**

- 编排器把本轮“脚本 + 约束”下发给 Gateway
- Gateway 与 gpt-realtime 交互，拿到音频流与文本字幕
- 编排器/网关将 `assistant_text`、`assistant_audio_started/ended` 写入 Timeline

**Step 8：写回快照**

- `SnapshotStore.Save(state)`（state 已包含该轮输出结果与时钟更新）

> 注：上面的 Step 3~7 一旦涉及外部调用（模型、工具、网关），必须有超时与取消语义（见第 7 节）。

---

## 6. Realtime Gateway 与 gpt-realtime：编排器如何“用语音，但不失控”

### 6.1 核心策略：gpt-realtime 是“语音设备”，不是“系统大脑”

正确分工：

- gpt-realtime：ASR / TTS（以及可选的受控文本生成）
- 编排器：推进节奏、工具裁决、硬约束、落库
- 导演：选拍点/动作/角色
- 演员：把“拍点计划”翻译成“台词脚本”

### 6.2 建链与会话生命周期（后端维护 Realtime 会话）

每个 session，Gateway 维护一个到 gpt-realtime 的连接（或一个可复用的连接池，但第一阶段可先 1:1）：

- 连接状态进入 Timeline（至少记录 `realtime_connected/realtime_disconnected`）
- 连接断开时的降级策略：
  - 语音降级为文本（仍可通过事件流推进）
  - 或提示用户稍后重试（但不要丢失事件）

### 6.3 ASR：为什么只用 asr_final 推进

原因：`asr_partial` 不稳定（会反复改写），若用于推进会导致导演误判与重复推进。

策略：

- `asr_partial`：仅用于 UI 字幕与“用户已开口”的提示
- `asr_final`：作为事实事件写入 Timeline，并触发推进

### 6.4 TTS/播报：输出边界事件是必需的

为了支持 OutputClock、插话中断与回放对齐，必须记录：

- `assistant_audio_started(turn_id, ts)`
- `assistant_audio_ended(turn_id, ts)`

以及对应字幕：

- `assistant_text(turn_id, text, ts)`

### 6.5 插话中断（barge-in）：必须有取消语义

当编排器收到 `barge_in`：

1. 立刻写入 Timeline（事实）
2. 取消当前输出（通过 Gateway 向 gpt-realtime 发送 cancel/stop）
3. 更新 state：降低 talk burst、提高 CHECK 权重、必要时回到上一拍点做校准

> 关键：barge-in 不是“UI 小功能”，它是语音对话的核心控制输入，必须进入导演状态机的信号面板。

---

## 7. 并发、取消、超时（工程落地的难点）

### 7.1 为什么必须串行，但又要“边播边听”

语音对话天然并发：

- 系统在播报（下行音频流）
- 用户随时插话（上行音频帧 + barge-in）

解决方式：

- **推进决策串行**：Director/Actor/Assessment 的“做决定”必须串行，避免错位
- **音频传输并发**：Gateway 的音频收发是 I/O 并发，但其“写入 Timeline 的事实事件”仍需通过 session worker 串行提交（或使用一个专门的 timeline append 队列）

### 7.2 取消语义（Cancel Tokens）

每次 assistant 输出都应该绑定一个 `turn_id` 与 `context.Context`：

- 新的 `asr_final` 到来或 `barge_in` 发生 → cancel 旧的输出上下文
- cancel 后仍要写入 Timeline：`assistant_audio_cancelled`（可选，但对调试很有帮助）

### 7.3 超时与兜底（第一阶段必须有）

外部依赖必须设置超时：

- Director（若接 Router LLM）
- Actor（若接文本模型）
- Realtime（ASR/TTS）
- Assessment（生成题目/评分）

超时兜底策略（示例）：

- Director 超时：使用 heuristic 默认 plan（CHECK + Recap）
- Actor 超时：使用模板兜底台词（短句 + 输出动作）
- Realtime 超时：返回纯文本（仍写 Timeline）

---

## 8. 工具交互如何进入同一条时间线（回答“能不能混在一个 API 中”）

### 8.1 结论

**必须混在一个会话通道里**，否则：

- 语音与答题无法对齐同一轮（turn_id/seq），回放与验收会崩；
- 插话中断会让工具状态错位（例如：题已出但用户插话打断，后端不知道该不该收题）。

### 8.2 工具事件的编排规则（第一阶段建议）

- `quiz_delivered`：由编排器写入（代表“系统确实出题了”）
- `quiz_answer`：由客户端上报，必须带 question_id/answer/client_ts
- `quiz_scored`：由编排器写入（规则评分也算 scored）

编排器以这些事件更新：

- misconception_tags（由选项映射）
- mastery_estimate（规则更新）
- output_quality（如要求“一句话解释”则按因果词/边界词打分）

---

## 9. Storage：TimelineStore + SnapshotStore（可回放落地）

### 9.1 两个存储的职责

- TimelineStore：append-only 事件流（事实源）
- SnapshotStore：最新 SessionState（缓存，加速加载）

### 9.2 接口建议（示意）

```go
type TimelineStore interface {
  Append(ctx context.Context, sessionID string, evt Event) (assignedSeq int64, err error)
  List(ctx context.Context, sessionID string, cursor string, limit int) (events []Event, nextCursor string, err error)
}

type SnapshotStore interface {
  Get(ctx context.Context, sessionID string) (*SessionState, error)
  Save(ctx context.Context, s *SessionState) error
}
```

### 9.3 回放策略

第一阶段可以先做“增量归约”：

- worker 内存持有 state
- 每 append 一个事件就 reduce 一次

当 worker 不存在或重启恢复时：

- 从 SnapshotStore 取快照 + cursor（可选）
- 从 TimelineStore 拉取 cursor 后事件并回放

---

## 10. 可观测性与验收统计（让“对话一等公民”可量化）

编排器应该产出以下关键指标（至少日志 + 可选 metrics）：

- `output_clock_sec` 分布（是否满足 90 秒约束）
- 每轮 `director_plan.next_beat/output_action` 分布（是否有结构化推进）
- `barge_in` 次数与发生位置（是否“压声播报”）
- `asr_final_latency_ms`（用户说完到拿到 final 的延迟）
- `assistant_first_audio_ms`（决定后到开始播报的延迟）
- 退出率、Exit Ticket 完成率、迁移题通过率

这些统计都应能从 Timeline 直接计算（这是验收的底座）。

---

## 11. 第一阶段实现清单（落地到工程任务）

按优先级：

1. 定义 Event schema（含 seq/turn_id/event_id），并固定“哪些事件是 Fact Events”
2. 实现 TimelineStore（先内存/文件）与 SnapshotStore（内存）
3. 实现 session worker：inbox 串行处理 + TTL 清理
4. 接入 Realtime Gateway（后端直连 gpt-realtime）：
   - asr_final → timeline → trigger
   - assistant audio/text → timeline → forward
   - barge-in cancel
5. Orchestrator 流水线（先 stub Director/Actor/Assessment）
6. Guardrails：90 秒输出 + “我懂了/结束”强制 Exit Ticket

